{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZcF0Za98xMW"
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime, timedelta\n",
        "from typing import List, Dict, Optional\n",
        "import uuid\n",
        "import random\n",
        "import threading\n",
        "import sys\n",
        "import os\n",
        "import socket\n",
        "import time\n",
        "import uuid\n",
        "import xmlrpc.client\n",
        "import xmlrpc.server as rpcserver\n",
        "import traceback\n",
        "import json\n",
        "from collections.abc import Callable\n",
        "import socketserver\n",
        "import asyncio\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esp3RIBWdOMu",
        "outputId": "3f5b86ce-667d-414a-9c37-09c68f236e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: keras\n",
            "Version: 3.8.0\n",
            "Summary: Multi-backend Keras\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: Keras team <keras-users@googlegroups.com>\n",
            "License: Apache License 2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: absl-py, h5py, ml-dtypes, namex, numpy, optree, packaging, rich\n",
            "Required-by: tensorflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEN3_ViFZf2m"
      },
      "outputs": [],
      "source": [
        "NODE_COUNT = 5\n",
        "SHARD_SIZE = 3\n",
        "AGGREGATOR_COUNT = 3\n",
        "FIRST_CLIENT = 26\n",
        "FOLD_INDEX = 3\n",
        "nodes = {}\n",
        "print_lock = threading.RLock()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PU3q_BtQ5pSs"
      },
      "outputs": [],
      "source": [
        "class Voting:\n",
        "  def __init__(self):\n",
        "    self.commits = {}\n",
        "    self.reveals = {}\n",
        "    self.res = 0\n",
        "\n",
        "  def commit(self, node_id, h):\n",
        "    self.commits[node_id] = h\n",
        "\n",
        "  def reveal(self, node_id, n):\n",
        "    self.reveals[node_id] = n\n",
        "\n",
        "  def verify_hash(self, h, n):\n",
        "    return h == hashlib.sha256(str(n).encode()).hexdigest()\n",
        "\n",
        "  def verify_voting(self):\n",
        "    for k in self.reveals.keys():\n",
        "      if k not in self.commits:\n",
        "        return False\n",
        "      if not self.verify_hash(self.commits[k], self.reveals[k]):\n",
        "        return False\n",
        "    shared_random_number = 0\n",
        "    for revealed_number in self.reveals.values():\n",
        "        shared_random_number ^= revealed_number\n",
        "    self.res = shared_random_number\n",
        "    return True\n",
        "\n",
        "  def result(self):\n",
        "    return self.res\n",
        "\n",
        "  def clear(self):\n",
        "    self.commits = {}\n",
        "    self.reveals = {}\n",
        "    self.res = 0\n",
        "\n",
        "class Elector:\n",
        "  def __init__(self, id: str):\n",
        "    self.id = id\n",
        "    self.random_number = 0\n",
        "    self.commitment = ''\n",
        "    self.voting = Voting()\n",
        "    self.sorting = []\n",
        "    self.election_pool = []\n",
        "\n",
        "  def start_election(self):\n",
        "    self.election_pool = list(nodes.keys())\n",
        "    self.start_voting()\n",
        "\n",
        "  def start_voting(self):\n",
        "    self.random_number = random.randint(0, len(self.election_pool) - 1)\n",
        "    self.commitment = hashlib.sha256(str(self.random_number).encode()).hexdigest()\n",
        "\n",
        "  def store_voting(self):\n",
        "    bit_count = len(bin(len(self.election_pool))[2:])\n",
        "    sum = 0\n",
        "    for i in range(0, bit_count):\n",
        "      sum += math.pow(2, i)\n",
        "    index = 0\n",
        "    if sum == 0:\n",
        "      index = 0\n",
        "    else:\n",
        "      index = math.floor(self.voting.result() / sum * max(0, len(self.election_pool) - 1))\n",
        "    self.sorting.append(self.election_pool[index])\n",
        "    self.election_pool.pop(index)\n",
        "    self.voting.clear()\n",
        "\n",
        "  def commit(self):\n",
        "    return self.commitment\n",
        "\n",
        "  def reveal(self):\n",
        "    return self.random_number\n",
        "\n",
        "  def start(self):\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeovZ3MBBAv1"
      },
      "outputs": [],
      "source": [
        "class Learner:\n",
        "  def __init__(self, my_address, my_dataset, model_arch):\n",
        "    self.my_address = my_address\n",
        "    self.all_initial_shares = {}\n",
        "    self.initial_share = []\n",
        "    self.model = []\n",
        "    self.model_arch = model_arch\n",
        "    self.dataset = my_dataset\n",
        "\n",
        "  def prepare_initial_share(self):\n",
        "    rand_layers = []\n",
        "    for layer in self.model_arch.layers:\n",
        "      weights = layer.get_weights()\n",
        "      rand_layer = []\n",
        "      for sublayer in weights:\n",
        "        rand_layer.append(sublayer)\n",
        "      rand_layers.append(rand_layer)\n",
        "    self.initial_share = rand_layers\n",
        "    self.all_initial_shares[self.my_address] = self.initial_share\n",
        "\n",
        "  def commit_other_initial_shares(self, node_id, share):\n",
        "    self.all_initial_shares[node_id] = share\n",
        "\n",
        "  def prepare_initial_model(self, list_of_concat):\n",
        "    layers = []\n",
        "    counter = 0\n",
        "    for i in range(0, len(self.all_initial_shares[self.my_address])):\n",
        "      weights = self.all_initial_shares[self.my_address][i]\n",
        "      sublayers = []\n",
        "      for j in range(0, len(weights)):\n",
        "        sublayer = weights[j]\n",
        "        sublayers.append(self.all_initial_shares[list_of_concat[counter]][i][j])\n",
        "        counter = (counter + 1) % len(list_of_concat)\n",
        "      layers.append(sublayers)\n",
        "    self.model = layers\n",
        "    for i in range(0, len(layers)):\n",
        "      self.model_arch.layers[i].set_weights(layers[i])\n",
        "\n",
        "  def clear(self):\n",
        "    self.all_initial_shares = {}\n",
        "    self.initial_share = []\n",
        "\n",
        "  def initial_train(self, X, y_one_hot):\n",
        "    self.model_arch.fit(X, y_one_hot, epochs=80, batch_size=64, validation_split=0.3)\n",
        "\n",
        "  def train(self):\n",
        "    self.model_arch.fit(self.dataset[0], self.dataset[1], validation_data=(self.dataset[2], self.dataset[3]), epochs=40, batch_size=64, validation_split=0.3, verbose=0)\n",
        "    layers = []\n",
        "    for layer in self.model_arch.layers:\n",
        "      weights = layer.get_weights()\n",
        "      sublayers = []\n",
        "      for sublayer in weights:\n",
        "        sublayers.append(sublayer)\n",
        "      layers.append(sublayers)\n",
        "    self.model = layers\n",
        "\n",
        "  def commit_final_model(self, model):\n",
        "    self.model = model\n",
        "    for i in range(0, len(model)):\n",
        "      self.model_arch.layers[i].set_weights(model[i])\n",
        "\n",
        "  def prepare_for_transfer(self):\n",
        "    for layer in self.model_arch.layers:\n",
        "      if isinstance(layer, Conv1D) or isinstance(layer, MaxPooling1D):\n",
        "        layer.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YS-PERUuU7Go"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "RANDOM_TRANSACTION_COUNT = 2   # How many transactions to generate for each event\n",
        "RANDOM_TRANSACTION_AMOUNT_MAX = 500  # Maximum amount in a random transaction\n",
        "RANDOM_TRANSACTION_AMOUNT_MIN = 10   # Minimum amount in a random transaction\n",
        "\n",
        "# Transaction: A statement of money transfer from a sender to a receiver.\n",
        "class Transaction:\n",
        "    def __init__(self, sender_address: str = '', payload: Dict = {}):\n",
        "        self.sender_address = sender_address       # ip:port of sender\n",
        "        self.payload = payload                     # payload\n",
        "\n",
        "    def from_dict(self, my_dict):\n",
        "        for key in my_dict:\n",
        "            setattr(self, key, my_dict[key])\n",
        "        return self\n",
        "\n",
        "# Event: Represents an event in the hashgraph.\n",
        "class Event:\n",
        "    def __init__(self,\n",
        "                 owner: str = '',\n",
        "                 signature: str = '',\n",
        "                 self_parent_hash: str = '',\n",
        "                 other_parent_hash: str = '',\n",
        "                 timestamp: float = 0,\n",
        "                 transactions: List[Transaction] = [],\n",
        "                 round: int = 0,\n",
        "                 is_witness: bool = False,\n",
        "                 is_famous: bool = False,\n",
        "                 is_fame_decided: bool = False,\n",
        "                 round_received: int = 0,\n",
        "                 consensus_timestamp: Optional[float] = 0):\n",
        "        self.owner = owner\n",
        "        self.signature = signature\n",
        "        self.self_parent_hash = self_parent_hash\n",
        "        self.other_parent_hash = other_parent_hash\n",
        "        self.timestamp = timestamp\n",
        "        self.transactions = transactions\n",
        "        self.round = round\n",
        "        self.is_witness = is_witness\n",
        "        self.is_famous = is_famous\n",
        "        self.is_fame_decided = is_fame_decided\n",
        "        self.round_received = round_received\n",
        "        self.consensus_timestamp = consensus_timestamp if consensus_timestamp else 0\n",
        "        self.latency = None  # To be set later\n",
        "\n",
        "    def from_dict(self, my_dict):\n",
        "        for key in my_dict:\n",
        "            setattr(self, key, my_dict[key])\n",
        "        for i in range(0, len(self.transactions)):\n",
        "            self.transactions[i] = Transaction().from_dict(self.transactions[i])\n",
        "        return self\n",
        "\n",
        "# SyncEventsDTO: Data Transfer Object for SyncAllEvents function\n",
        "class SyncEventsDTO:\n",
        "    def __init__(self, sender_address: str = '', missing_events: Dict[str, List[Event]] = {}):\n",
        "        self.sender_address = sender_address  # address of the node who made the call\n",
        "        self.missing_events = missing_events  # map of addresses to events of those addresses that are missing on the remotely called node\n",
        "\n",
        "    def from_dict(self, my_dict):\n",
        "        for key in my_dict:\n",
        "            setattr(self, key, my_dict[key])\n",
        "        for key in self.missing_events:\n",
        "            for i in range(0, len(self.missing_events[key])):\n",
        "                self.missing_events[key][i] = Event().from_dict(self.missing_events[key][i])\n",
        "        return self\n",
        "\n",
        "class HgNode:\n",
        "    def __init__(self, initial_hashgraph: Dict[str, List[Event]], address: str, my_dataset: List[float], model_arch):\n",
        "        self.lock = threading.RLock()\n",
        "        self.address = address  # ip:port of the peer\n",
        "        self.hashgraph: Dict[str, List[Event]] = initial_hashgraph  # local copy of hashgraph\n",
        "        self.events: Dict[str, Event] = {}\n",
        "        self.witnesses: Dict[str, Dict[int, Event]] = {}\n",
        "        self.first_round_of_fame_undecided: Dict[str, int] = {}\n",
        "        self.first_event_of_not_consensus_index: Dict[str, int] = {}\n",
        "        self.consensus_events: List[Event] = []\n",
        "        self.transaction_buffer: List[Transaction] = []\n",
        "        self.see_dp_memory: Dict[str, Dict[str, bool]] = {}  # p.Signature -> q.Signature -> bool\n",
        "        self.on_commit_received: Callable = None\n",
        "        self.on_reveal_received: Callable = None\n",
        "        self.on_voting_next_round: Callable = None\n",
        "        self.elector = Elector(address)\n",
        "        self.voting_round_dones: Dict[str, bool] = {}\n",
        "        self.shared_order: List[str] = []\n",
        "        self.learner = Learner(address, my_dataset, model_arch)\n",
        "\n",
        "    def ping(self):\n",
        "        return \"pong\"\n",
        "\n",
        "    def voting_commit(self, sender_address: str, h: str, success: Optional[bool] = None):\n",
        "      self.elector.voting.commit(sender_address, h)\n",
        "      self.on_commit_received()\n",
        "      success = True\n",
        "      return True\n",
        "\n",
        "    def voting_reveal(self, sender_address: str, n: int, success: Optional[bool] = None):\n",
        "      self.elector.voting.reveal(sender_address, n)\n",
        "      self.on_reveal_received()\n",
        "      success = True\n",
        "      return True\n",
        "\n",
        "    def voting_done(self, sender_address: str, success: Optional[bool] = None):\n",
        "      self.voting_round_dones[sender_address] = True\n",
        "      self.on_voting_next_round()\n",
        "      success = True\n",
        "      return True\n",
        "\n",
        "    # GetNumberOfMissingEvents: Node A calls Node B to learn which events B does not know and A knows.\n",
        "    def get_number_of_missing_events(self, num_events_already_known: Dict[str, int], num_events_to_send: Optional[Dict[str, int]] = None) -> None:\n",
        "        if num_events_to_send is None:\n",
        "            num_events_to_send = {}\n",
        "        with self.lock:\n",
        "            for addr in self.hashgraph:\n",
        "                num_events_to_send[addr] = num_events_already_known.get(addr, 0) - len(self.hashgraph[addr])\n",
        "        return num_events_to_send\n",
        "\n",
        "    # SyncAllEvents: Node A first calls GetNumberOfMissingEvents on B, and then sends the missing events in this function\n",
        "    def sync_all_events(self, events: SyncEventsDTO, success: Optional[bool] = None) -> bool:\n",
        "        try:\n",
        "\n",
        "          # events = SyncEventsDTO().from_dict(events)\n",
        "\n",
        "          with self.lock:\n",
        "              other_peer_addresses = [addr for addr in self.hashgraph if addr != self.address]\n",
        "              #transactions = self.generate_transactions(RANDOM_TRANSACTION_COUNT, RANDOM_TRANSACTION_AMOUNT_MAX, RANDOM_TRANSACTION_AMOUNT_MIN, other_peer_addresses)\n",
        "\n",
        "              # Add the missing events to my local hashgraph\n",
        "              for addr, missing_events in events.missing_events.items():\n",
        "                for missing_event in missing_events:\n",
        "                  if missing_event.signature not in self.events:\n",
        "                    self.hashgraph.setdefault(addr, []).append(missing_event)\n",
        "                    self.events[missing_event.signature] = missing_event\n",
        "                    if missing_event.is_witness:\n",
        "                      self.witnesses.setdefault(missing_event.owner, {})[missing_event.round] = missing_event\n",
        "\n",
        "              # Store the transactions temporarily, and reset the global buffer\n",
        "              transactions = []\n",
        "              transactions.extend(self.transaction_buffer)\n",
        "              self.transaction_buffer = []\n",
        "\n",
        "              # Create random signature\n",
        "              signature = str(uuid.uuid4())\n",
        "\n",
        "              # Assign parents\n",
        "              new_events_self_parent = self.hashgraph[self.address][-1]\n",
        "              new_events_other_parent = self.hashgraph[events.sender_address][-1]\n",
        "\n",
        "              if len(transactions) > 0:\n",
        "                # Create event\n",
        "                new_event = Event(\n",
        "                  owner=self.address,\n",
        "                  signature=signature,\n",
        "                  self_parent_hash=new_events_self_parent.signature,\n",
        "                  other_parent_hash=new_events_other_parent.signature,\n",
        "                  timestamp=datetime.now().timestamp(),\n",
        "                  transactions=transactions\n",
        "                )\n",
        "\n",
        "                # Find the round & witness of new event\n",
        "                self.divide_rounds(new_event)\n",
        "\n",
        "                # Update local arrays\n",
        "                if new_event.is_witness:\n",
        "                  self.witnesses.setdefault(new_event.owner, {})[new_event.round] = new_event\n",
        "                self.events[new_event.signature] = new_event\n",
        "                self.hashgraph.setdefault(self.address, []).append(new_event)\n",
        "\n",
        "              # Decide fame on fame-undecided witnesses\n",
        "              self.decide_fame()\n",
        "\n",
        "              # Arrive to consensus on order of events\n",
        "              self.find_order()\n",
        "\n",
        "              if success is not None:\n",
        "                success = True\n",
        "              return True\n",
        "        except Exception as e:\n",
        "          with print_lock:\n",
        "            print(traceback.format_exc())\n",
        "          raise e\n",
        "\n",
        "    # DivideRounds: Calculates the round of a new event\n",
        "    def divide_rounds(self, event: Event) -> None:\n",
        "        self_parent = self.events.get(event.self_parent_hash)\n",
        "        other_parent = self.events.get(event.other_parent_hash)\n",
        "        if not self_parent or not other_parent:\n",
        "            with print_lock:\n",
        "              print(f\"Parents were not ok: (self: {self_parent is not None}, other: {other_parent is not None})\")\n",
        "            return\n",
        "\n",
        "        # Round of this event is at least the round of its parents\n",
        "        r = max(self_parent.round, other_parent.round)\n",
        "\n",
        "        # Get round r witnesses\n",
        "        witnesses = self.find_witnesses_of_a_round(r)\n",
        "\n",
        "        # Count strongly seen witnesses in round r\n",
        "        strongly_seen_witness_count = 0\n",
        "        for w in witnesses.values():\n",
        "            if self.strongly_see(event, w):\n",
        "                strongly_seen_witness_count += 1\n",
        "\n",
        "        # Check supermajority\n",
        "        if float(strongly_seen_witness_count) > (2.0 * len(self.hashgraph) / 3.0):\n",
        "            event.round = r + 1\n",
        "        else:\n",
        "            event.round = r\n",
        "\n",
        "        # Check if this new event is a witness\n",
        "        if event.round > self_parent.round:\n",
        "            event.is_witness = True\n",
        "\n",
        "    # DecideFame: Decides if a witness is famous or not\n",
        "    def decide_fame(self) -> None:\n",
        "        # Get the last witnesses that do not have a decided fame\n",
        "        fame_undecided_witnesses: List[Event] = []\n",
        "        for addr in self.hashgraph:\n",
        "            for round_num, witness in self.witnesses.get(addr, {}).items():\n",
        "                if round_num >= self.first_round_of_fame_undecided.get(addr, 0):\n",
        "                    fame_undecided_witnesses.append(witness)\n",
        "\n",
        "        for e in fame_undecided_witnesses:\n",
        "            # Get all witnesses that have greater rounds\n",
        "            witnesses_with_greater_rounds: List[Event] = []\n",
        "            for addr in self.hashgraph:\n",
        "                for round_num, witness in self.witnesses.get(addr, {}).items():\n",
        "                    if round_num > e.round:\n",
        "                        witnesses_with_greater_rounds.append(witness)\n",
        "\n",
        "            for w in witnesses_with_greater_rounds:\n",
        "                # Find witnesses of prior round\n",
        "                witnesses_of_round = self.find_witnesses_of_a_round(w.round - 1)\n",
        "\n",
        "                # Choose the strongly seen ones\n",
        "                strongly_seen_witnesses_of_round: List[Event] = []\n",
        "                for wr in witnesses_of_round.values():\n",
        "                    if self.strongly_see(w, wr):\n",
        "                        strongly_seen_witnesses_of_round.append(wr)\n",
        "\n",
        "                # Count votes\n",
        "                votes = [self.see(voter, e) for voter in strongly_seen_witnesses_of_round]\n",
        "                majority = sum(1 if vote else -1 for vote in votes)\n",
        "                true_votes = votes.count(True)\n",
        "                false_votes = votes.count(False)\n",
        "                majority_vote = majority >= 0\n",
        "                super_majority_threshold = 2.0 * len(self.hashgraph) / 3.0\n",
        "                if ((majority_vote and float(true_votes) > super_majority_threshold) or\n",
        "                    (not majority_vote and float(false_votes) > super_majority_threshold)):\n",
        "                    e.is_famous = majority_vote\n",
        "                    e.is_fame_decided = True\n",
        "                    self.first_round_of_fame_undecided[e.owner] = e.round + 1\n",
        "                    break\n",
        "\n",
        "    # FindOrder: Arrive at a consensus on the order of events\n",
        "    def find_order(self) -> None:\n",
        "        # Find events\n",
        "        non_consensus_events: List[Event] = []\n",
        "        for addr in self.hashgraph:\n",
        "            index = self.first_event_of_not_consensus_index.get(addr, 0)\n",
        "            non_consensus_events.extend(self.hashgraph[addr][index:])\n",
        "\n",
        "        for e in non_consensus_events:\n",
        "            # First & Third conditions: find a valid round number\n",
        "            r = self.first_round_of_fame_undecided.get(e.owner, 0)\n",
        "            for round_num in self.first_round_of_fame_undecided.values():\n",
        "                if round_num < r:\n",
        "                    r = round_num\n",
        "\n",
        "            witnesses = self.find_witnesses_of_a_round(r)\n",
        "            if witnesses:\n",
        "                # Second condition: make sure x is seen by all famous witnesses\n",
        "                cond_met = all(not w.is_famous or self.see(w, e) for w in witnesses.values())\n",
        "                if cond_met:\n",
        "                    # Construct consensus set\n",
        "                    s: List[Event] = []\n",
        "                    for w in witnesses.values():\n",
        "                        z = w\n",
        "                        while not is_initial(z):\n",
        "                            if z.round < e.round:\n",
        "                                break\n",
        "                            if self.see(z, e) and not self.see(self.events.get(z.self_parent_hash), e):\n",
        "                                s.append(z)\n",
        "                            z = self.events.get(z.self_parent_hash)\n",
        "                            if z is None:\n",
        "                                break\n",
        "\n",
        "                    if s:\n",
        "                        e.round_received = r\n",
        "                        # Take median\n",
        "                        sorted_timestamps = sorted([se.timestamp for se in s])\n",
        "                        median_timestamp = sorted_timestamps[len(sorted_timestamps) // 2]\n",
        "                        e.consensus_timestamp = median_timestamp\n",
        "                        e.latency = datetime.now().timestamp() - e.timestamp  # Event's timestamp was set during its creation\n",
        "                        self.consensus_events.append(e)\n",
        "                        self.first_event_of_not_consensus_index[e.owner] = self.first_event_of_not_consensus_index.get(e.owner, 0) + 1\n",
        "\n",
        "        # Bring all consensus events ordered\n",
        "        self.consensus_events.sort(key=lambda x: (x.round_received, x.consensus_timestamp))\n",
        "\n",
        "    # see: If we can reach target using downward edges only, we can see it.\n",
        "    def see(self, current: Event, target: Event) -> bool:\n",
        "        dp_map = self.see_dp_memory.setdefault(current.signature, {})\n",
        "        if target.signature in dp_map:\n",
        "            return dp_map[target.signature]\n",
        "\n",
        "        if (current.signature == target.signature or\n",
        "            (current.round > target.round and current.owner == target.owner)):\n",
        "            dp_map[target.signature] = True\n",
        "            return True\n",
        "        if (current.round < target.round or\n",
        "            (current.is_witness and current.round == target.round) or\n",
        "            is_initial(current)):\n",
        "            dp_map[target.signature] = False\n",
        "            return False\n",
        "\n",
        "        # Recursive check\n",
        "        self_parent = self.events.get(current.self_parent_hash)\n",
        "        other_parent = self.events.get(current.other_parent_hash)\n",
        "        result = False\n",
        "        if self_parent:\n",
        "            result = self.see(self_parent, target)\n",
        "        if not result and other_parent:\n",
        "            result = self.see(other_parent, target)\n",
        "        dp_map[target.signature] = result\n",
        "        return result\n",
        "\n",
        "    # stronglySee: If we see the target, and we go through 2n/3 different nodes as we do that,\n",
        "    # we say we strongly see that target. This function is used for choosing the famous witness\n",
        "    def strongly_see(self, current: Event, target: Event) -> bool:\n",
        "        latest_ancestors = self.get_latest_ancestor_from_all_nodes(current, target.round)\n",
        "        count = sum(1 for ancestor in latest_ancestors.values() if self.see(ancestor, target))\n",
        "        return float(count) > (2.0 * len(self.hashgraph) / 3.0)\n",
        "\n",
        "    # get_latest_ancestor_from_all_nodes: Do breadth first search to find the latest ancestor that event e can see on every node\n",
        "    def get_latest_ancestor_from_all_nodes(self, e: Event, min_round: int) -> Dict[str, Event]:\n",
        "        latest_ancestors: Dict[str, Event] = {}\n",
        "        if not is_initial(e):\n",
        "            queue: List[Event] = [e]\n",
        "            while queue:\n",
        "                current_event = queue.pop(0)\n",
        "\n",
        "                current_ancestor = latest_ancestors.get(current_event.owner)\n",
        "                if not current_ancestor:\n",
        "                    latest_ancestors[current_event.owner] = current_event\n",
        "                elif (current_event.round > current_ancestor.round and\n",
        "                      current_event.owner == current_ancestor.owner):\n",
        "                    latest_ancestors[current_event.owner] = current_event\n",
        "                elif (current_event.round >= current_ancestor.round and\n",
        "                      self.see(current_event, current_ancestor)):\n",
        "                    latest_ancestors[current_event.owner] = current_event\n",
        "\n",
        "                if not is_initial(current_event):\n",
        "                    self_parent = self.events.get(current_event.self_parent_hash)\n",
        "                    other_parent = self.events.get(current_event.other_parent_hash)\n",
        "                    if self_parent and self_parent.round >= min_round:\n",
        "                        queue.append(self_parent)\n",
        "                    if other_parent and other_parent.round >= min_round:\n",
        "                        queue.append(other_parent)\n",
        "        return latest_ancestors\n",
        "\n",
        "    # find_witnesses_of_a_round: Find witnesses of round r, which is the first event with round r in every node\n",
        "    def find_witnesses_of_a_round(self, r: int) -> Dict[str, Event]:\n",
        "        witnesses = {}\n",
        "        for addr in self.hashgraph:\n",
        "            witness = self.witnesses.get(addr, {}).get(r)\n",
        "            if witness:\n",
        "                witnesses[addr] = witness\n",
        "        return witnesses\n",
        "\n",
        "    # GenerateTransactions: Generates an arbitrary amount of random transactions\n",
        "    def generate_transactions(self, count: int, max_amount: float, min_amount: float, peer_addresses: List[str]) -> List[Transaction]:\n",
        "        transactions = []\n",
        "        for _ in range(count):\n",
        "            transactions.append(Transaction(\n",
        "                sender_address=self.address,\n",
        "                payload={'hello': 'world'},\n",
        "            ))\n",
        "        return transactions\n",
        "\n",
        "# Helper Functions\n",
        "\n",
        "# is_initial: Returns true if given event is an initial event, false otherwise.\n",
        "def is_initial(e: Event) -> bool:\n",
        "    return e.self_parent_hash == \"\" or e.other_parent_hash == \"\"\n",
        "\n",
        "# Handle error: In Python, exceptions are used instead of panic.\n",
        "def handle_error(e: Exception) -> None:\n",
        "    if e:\n",
        "        raise e\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecxfZiR7VkYf"
      },
      "outputs": [],
      "source": [
        "EVALUATION_MODE = True  # Flag to indicate evaluation mode. Performance metrics are measured and printed in evaluation mode.\n",
        "GOSSIP_WAIT_TIME = 0.1  # Seconds between each random gossip\n",
        "CONNECTION_ATTEMPT_DELAY_TIME = 0.1  # Seconds between each connection attempt\n",
        "PRINT_PER_MRPC_CALL = 20  # After this many RPC calls, print out evaluations\n",
        "\n",
        "class SimpleThreadedXMLRPCServer(socketserver.ThreadingMixIn, rpcserver.SimpleXMLRPCServer):\n",
        "    pass\n",
        "\n",
        "class DLedger:\n",
        "    \"\"\"\n",
        "    DLedger: Class for a member of the distributed ledger\n",
        "    \"\"\"\n",
        "    def __init__(self, node: HgNode, my_address: str, peer_addresses: List[str], peer_address_map: Dict[str, str]):\n",
        "        self.node = node\n",
        "        self.my_address = my_address\n",
        "        self.peer_addresses = peer_addresses\n",
        "        self.peer_address_map = peer_address_map\n",
        "        self.peer_client_map = {}\n",
        "        self.on_election_done = None\n",
        "        self.global_model_ready = None\n",
        "        self.shard = None\n",
        "        self.is_aggregator = False\n",
        "        self.shard_aggregators = {}\n",
        "        self.client_locks = {}\n",
        "\n",
        "    @staticmethod\n",
        "    def new_dledger_from_peers(port: str, peer_address_map: Dict[str, str], my_dataset: List[float], model_arch) -> 'DLedger':\n",
        "        local_ip_address = get_local_address()\n",
        "        my_address = f\"{local_ip_address}:{port}\"\n",
        "        # Assert that your own address is in the peers file\n",
        "        if my_address not in peer_address_map:\n",
        "            raise Exception(f\"Peers file does not include my address: {my_address}\")\n",
        "\n",
        "        # Copy peer addresses to a list for random access during gossip\n",
        "        peer_addresses = [addr for addr in peer_address_map if addr != my_address]\n",
        "\n",
        "        # Setup the Hashgraph\n",
        "        signature_uuid = uuid.uuid4()\n",
        "        signature = str(signature_uuid)\n",
        "\n",
        "        initial_hashgraph = {addr: [] for addr in peer_address_map}  # We should not know any event other than our own event at the start\n",
        "        initial_event = Event(\n",
        "            owner=my_address,\n",
        "            signature=signature,\n",
        "            self_parent_hash=\"\",\n",
        "            other_parent_hash=\"\",\n",
        "            timestamp=time.time(),\n",
        "            transactions=[],\n",
        "            round=1,\n",
        "            is_witness=True,  # True because the initial event is the first event of its round\n",
        "            is_famous=False,\n",
        "            is_fame_decided=False,\n",
        "            round_received=0,\n",
        "            consensus_timestamp=0\n",
        "        )\n",
        "        initial_hashgraph[my_address].append(initial_event)\n",
        "        my_node = HgNode(initial_hashgraph, my_address, my_dataset, model_arch)\n",
        "\n",
        "        for addr in my_node.hashgraph:\n",
        "            my_node.witnesses[addr] = {}\n",
        "            my_node.first_event_of_not_consensus_index[addr] = 0  # Index 0 for the initial event\n",
        "\n",
        "        my_node.witnesses[initial_event.owner][1] = initial_event\n",
        "        my_node.events[initial_event.signature] = initial_event\n",
        "        my_node.first_round_of_fame_undecided[initial_event.owner] = 1\n",
        "\n",
        "        # Setup the server\n",
        "        server = SimpleThreadedXMLRPCServer((my_address.split(\":\")[0], int(my_address.split(\":\")[1])), allow_none=True, logRequests=False)\n",
        "        server.register_instance(my_node)\n",
        "        threading.Thread(target=listen_for_rpc_connections, args=(server,), daemon=True).start()\n",
        "\n",
        "        return DLedger(\n",
        "            node=my_node,\n",
        "            my_address=my_address,\n",
        "            peer_addresses=peer_addresses,\n",
        "            peer_address_map=peer_address_map\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def new_dledger(port: str, peers_file_path: str, my_dataset: List[float], model_arch) -> 'DLedger':\n",
        "        local_ip_address = get_local_address()\n",
        "        peer_address_map = read_peer_addresses(peers_file_path, local_ip_address)\n",
        "        dl = DLedger.new_dledger_from_peers(port, peer_address_map, my_dataset, model_arch)\n",
        "        dl.node.on_commit_received = dl.try_share_reveal\n",
        "        dl.node.on_reveal_received = dl.try_validate_election\n",
        "        dl.node.on_voting_next_round = dl.try_voting_next_round\n",
        "        dl.on_election_done = None\n",
        "        dl.global_model_ready = None\n",
        "        dl.local_models_all_ready = None\n",
        "        dl.shard_models_all_ready = None\n",
        "        dl.global_models_all_ready = None\n",
        "        return dl\n",
        "\n",
        "    def start(self):\n",
        "        threading.Thread(target=gossip_routine, args=(self.node, self.peer_addresses), daemon=True).start()\n",
        "\n",
        "    def perform_transaction(self, payload: Dict):\n",
        "        with self.node.lock:\n",
        "            transaction = Transaction(\n",
        "                sender_address=self.my_address,\n",
        "                payload=payload,\n",
        "            )\n",
        "            self.node.transaction_buffer.append(transaction)\n",
        "\n",
        "    def wait_for_peers(self):\n",
        "        peer_available = [False] * len(self.peer_addresses)\n",
        "        remaining_peers = len(self.peer_addresses)\n",
        "        with print_lock:\n",
        "            print(\"waiting...\\n\")\n",
        "        while remaining_peers > 0:\n",
        "            for index, has_already_responded in enumerate(peer_available):\n",
        "                if has_already_responded:\n",
        "                    continue\n",
        "                try:\n",
        "                    proxy = xmlrpc.client.ServerProxy(f\"http://{self.peer_addresses[index]}\", allow_none=True)\n",
        "                    self.peer_client_map[self.peer_addresses[index]] = proxy\n",
        "                    self.client_locks[self.peer_addresses[index]] = threading.RLock()\n",
        "                    proxy.ping()  # Assuming there's a ping method\n",
        "                    peer_available[index] = True\n",
        "                    remaining_peers -= 1\n",
        "                except Exception as err:\n",
        "                    with print_lock:\n",
        "                        print(err)\n",
        "                    time.sleep(CONNECTION_ATTEMPT_DELAY_TIME)\n",
        "\n",
        "    def try_validate_election(self):\n",
        "      if len(self.node.elector.voting.reveals) == NODE_COUNT:\n",
        "        if not self.node.elector.voting.verify_voting():\n",
        "          raise 'voting validation failed'\n",
        "        self.node.elector.store_voting()\n",
        "        self.node.voting_round_dones[self.my_address] = True\n",
        "        def send_req(addr):\n",
        "          nodes[addr].node.voting_done(self.my_address)\n",
        "          # with xmlrpc.client.ServerProxy(f\"http://{addr}\", allow_none=True) as proxy:\n",
        "          #   proxy.voting_done(self.my_address)\n",
        "        for addr in self.peer_addresses:\n",
        "          send_req(addr)\n",
        "        self.try_voting_next_round()\n",
        "\n",
        "    def try_share_reveal(self):\n",
        "      if len(self.node.elector.voting.commits) == NODE_COUNT:\n",
        "        self.node.elector.voting.reveal(self.my_address, self.node.elector.reveal())\n",
        "        def send_req(addr):\n",
        "          nodes[addr].node.voting_reveal(self.my_address, self.node.elector.reveal())\n",
        "          # with xmlrpc.client.ServerProxy(f\"http://{addr}\", allow_none=True) as proxy:\n",
        "          #   proxy.voting_reveal(self.my_address, self.node.elector.reveal())\n",
        "        for addr in self.peer_addresses:\n",
        "          send_req(addr)\n",
        "      self.try_validate_election()\n",
        "\n",
        "    def try_voting_next_round(self):\n",
        "      if len(self.node.voting_round_dones) == NODE_COUNT:\n",
        "        self.node.voting_round_dones = {}\n",
        "        if len(self.node.elector.sorting) < NODE_COUNT:\n",
        "          self.node.elector.start_voting()\n",
        "          self.share_my_commit()\n",
        "        else:\n",
        "          self.node.shared_order = self.node.elector.sorting\n",
        "          self.node.elector.sorting = []\n",
        "          self.on_election_done()\n",
        "\n",
        "    def start_election(self):\n",
        "      self.node.shared_order = []\n",
        "      self.node.elector.start_election()\n",
        "      with print_lock:\n",
        "        print(\"election started\")\n",
        "      self.share_my_commit()\n",
        "\n",
        "    def start_voting(self):\n",
        "      self.node.elector.start_voting()\n",
        "\n",
        "    def share_my_commit(self):\n",
        "      self.node.elector.voting.commit(self.my_address, self.node.elector.commit())\n",
        "      def send_req(addr):\n",
        "        nodes[addr].node.voting_commit(self.my_address, self.node.elector.commit())\n",
        "        # with xmlrpc.client.ServerProxy(f\"http://{addr}\", allow_none=True) as proxy:\n",
        "        #   proxy.voting_commit(self.my_address, self.node.elector.commit())\n",
        "      for addr in self.peer_addresses:\n",
        "        send_req(addr)\n",
        "      self.try_share_reveal()\n",
        "\n",
        "    def share_initial_weights(self):\n",
        "      self.node.learner.prepare_initial_share()\n",
        "      self.perform_transaction({\n",
        "          'type': 'initial_model_share',\n",
        "          'creator_address': self.my_address,\n",
        "          'weights': self.node.learner.initial_share\n",
        "      })\n",
        "      t = threading.Thread(target=check_for_all_shares, args=(self.my_address, self))\n",
        "      t.start()\n",
        "\n",
        "    def local_model_to_hashgraph(self):\n",
        "      self.perform_transaction({\n",
        "          'type': 'local_model',\n",
        "          'creator_address': self.my_address,\n",
        "          'weights': self.node.learner.model\n",
        "      })\n",
        "      t = threading.Thread(target=check_for_all_local_models, args=(self.my_address, self))\n",
        "      t.start()\n",
        "\n",
        "    def find_my_shard(self):\n",
        "      self.shard = int(math.floor(self.node.shared_order.index(self.my_address) / SHARD_SIZE))\n",
        "      self.is_aggregator = (self.node.shared_order.index(self.my_address) % SHARD_SIZE) < AGGREGATOR_COUNT\n",
        "      self.shard_aggregators = {}\n",
        "      if self.is_aggregator:\n",
        "        self.shard_aggregators[self.my_address] = self.shard\n",
        "      for addr in self.peer_addresses:\n",
        "        s = int(math.floor(self.node.shared_order.index(addr) / SHARD_SIZE))\n",
        "        ig = (self.node.shared_order.index(addr) % SHARD_SIZE) < AGGREGATOR_COUNT\n",
        "        if ig:\n",
        "          self.shard_aggregators[addr] = s\n",
        "\n",
        "    def check_and_start_shard_aggregation(self):\n",
        "      try:\n",
        "        if self.is_aggregator:\n",
        "          list_of_events = list(self.node.events.values())\n",
        "          list_of_events.sort(key=lambda x: x.timestamp)\n",
        "          shard_local_models = []\n",
        "          for event in list_of_events:\n",
        "            for trx in event.transactions:\n",
        "              if ('type' in trx.payload) and (trx.payload['type'] == 'local_model'):\n",
        "                s = int(math.floor(self.node.shared_order.index(trx.payload['creator_address']) / SHARD_SIZE))\n",
        "                if s == self.shard:\n",
        "                  shard_local_models.append(trx.payload['weights'])\n",
        "          layers = []\n",
        "          for i in range(0, len(shard_local_models[0])):\n",
        "            sublayers = []\n",
        "            for j in range(0, len(shard_local_models[0][i])):\n",
        "              sublayers.append(np.mean(np.array([model[i][j] for model in shard_local_models]), axis=0))\n",
        "            layers.append(sublayers)\n",
        "          shard_mean_model = layers\n",
        "          self.perform_transaction({\n",
        "            'type': 'shard_model',\n",
        "            'creator_address': self.my_address,\n",
        "            'weights': shard_mean_model,\n",
        "            'shard': self.shard\n",
        "          })\n",
        "        t = threading.Thread(target=check_for_all_shard_models, args=(self.my_address, self))\n",
        "        t.start()\n",
        "      except Exception as e:\n",
        "        with print_lock:\n",
        "          print(traceback.format_exc())\n",
        "        raise e\n",
        "\n",
        "    def check_and_start_global_aggregation(self):\n",
        "      try:\n",
        "        is_global_aggregator = self.node.shared_order.index(self.my_address) < AGGREGATOR_COUNT\n",
        "        if is_global_aggregator:\n",
        "          list_of_events = list(self.node.events.values())\n",
        "          list_of_events.sort(key=lambda x: x.timestamp)\n",
        "          shard_models = {}\n",
        "          for s in self.shard_aggregators.values():\n",
        "            if s not in shard_models:\n",
        "              shard_models[s] = []\n",
        "          for event in list_of_events:\n",
        "            for trx in event.transactions:\n",
        "              if ('type' in trx.payload) and (trx.payload['type'] == 'shard_model'):\n",
        "                s = trx.payload['shard']\n",
        "                shard_models[s].append(trx.payload['weights'])\n",
        "          shard_chosen_models = []\n",
        "          for s in shard_models.keys():\n",
        "            groups = {}\n",
        "            counter = 0\n",
        "            for w in shard_models[s]:\n",
        "              if len(groups) == 0:\n",
        "                groups[str(counter)] = [w]\n",
        "                counter += 1\n",
        "              else:\n",
        "                found = False\n",
        "                for g_key in groups.keys():\n",
        "                  if compare_weights(groups[g_key][0], w):\n",
        "                    groups[g_key].append(w)\n",
        "                    found = True\n",
        "                    break\n",
        "                if not found:\n",
        "                  groups[str(counter)] = [w]\n",
        "                  counter += 1\n",
        "            if len(groups.keys()) > 1:\n",
        "              raise \"attack !\"\n",
        "            max_vote_key = None\n",
        "            for g_key in groups.keys():\n",
        "              if max_vote_key == None:\n",
        "                max_vote_key = g_key\n",
        "              elif len(groups[g_key]) > len(groups[max_vote_key]):\n",
        "                max_vote_key = g_key\n",
        "            shard_chosen_models.append(groups[max_vote_key][0])\n",
        "          layers = []\n",
        "          for i in range(0, len(shard_chosen_models[0])):\n",
        "            sublayers = []\n",
        "            for j in range(0, len(shard_chosen_models[0][i])):\n",
        "              sublayers.append(np.mean(np.array([model[i][j] for model in shard_chosen_models]), axis=0))\n",
        "            layers.append(sublayers)\n",
        "          global_mean_model = layers\n",
        "          self.perform_transaction({\n",
        "            'type': 'global_model',\n",
        "            'creator_address': self.my_address,\n",
        "            'weights': global_mean_model\n",
        "          })\n",
        "      except Exception as e:\n",
        "        with print_lock:\n",
        "          print(traceback.format_exc())\n",
        "        raise e\n",
        "      t = threading.Thread(target=check_for_all_global_models, args=(self.my_address, self))\n",
        "      t.start()\n",
        "\n",
        "    def aggerate_my_final_model(self):\n",
        "      try:\n",
        "        list_of_events = list(self.node.events.values())\n",
        "        list_of_events.sort(key=lambda x: x.timestamp)\n",
        "        global_models = []\n",
        "        for event in list_of_events:\n",
        "          for trx in event.transactions:\n",
        "            if ('type' in trx.payload) and (trx.payload['type'] == 'global_model'):\n",
        "              global_models.append(trx.payload['weights'])\n",
        "        final_chosen_model = None\n",
        "        groups = {}\n",
        "        counter = 0\n",
        "        for w in global_models:\n",
        "          if len(groups) == 0:\n",
        "            groups[str(counter)] = [w]\n",
        "            counter += 1\n",
        "          else:\n",
        "            found = False\n",
        "            for g_key in groups.keys():\n",
        "              if compare_weights(groups[g_key][0], w):\n",
        "                groups[g_key].append(w)\n",
        "                found = True\n",
        "                break\n",
        "            if not found:\n",
        "              groups[str(counter)] = [w]\n",
        "              counter += 1\n",
        "        if len(groups.keys()) > 1:\n",
        "          raise \"attack !\"\n",
        "        max_vote_key = None\n",
        "        for g_key in groups.keys():\n",
        "          if max_vote_key == None:\n",
        "            max_vote_key = g_key\n",
        "          elif len(groups[g_key]) > len(groups[max_vote_key]):\n",
        "            max_vote_key = g_key\n",
        "        final_chosen_model = groups[max_vote_key][0]\n",
        "        self.node.learner.commit_final_model(final_chosen_model)\n",
        "      except Exception as e:\n",
        "        with print_lock:\n",
        "          print(traceback.format_exc())\n",
        "        raise e\n",
        "\n",
        "def compare_weights(w1, w2):\n",
        "  for i in range(0, len(w1)):\n",
        "    for j in range(0, len(w1[i])):\n",
        "      if not (w1[i][j] == w2[i][j]).all():\n",
        "        return False\n",
        "  return True\n",
        "\n",
        "def check_for_all_global_models(address: str, ledger: DLedger):\n",
        "  with print_lock:\n",
        "    print(\"checking for other global models as \" + address + \"\\n\")\n",
        "  while True:\n",
        "    time.sleep(1)\n",
        "    list_of_events = list(ledger.node.events.values())\n",
        "    list_of_events.sort(key=lambda x: x.timestamp)\n",
        "    all_shared_nodes = {}\n",
        "    for event in list_of_events:\n",
        "      for trx in event.transactions:\n",
        "        if ('type' in trx.payload) and (trx.payload['type'] == 'global_model'):\n",
        "          all_shared_nodes[trx.payload['creator_address']] = True\n",
        "    if len(all_shared_nodes) == AGGREGATOR_COUNT:\n",
        "      break\n",
        "  ledger.global_models_all_ready()\n",
        "\n",
        "def check_for_all_shard_models(address: str, ledger: DLedger):\n",
        "  with print_lock:\n",
        "    print(\"checking for other shard models as \" + address + \"\\n\")\n",
        "  while True:\n",
        "    time.sleep(1)\n",
        "    list_of_events = list(ledger.node.events.values())\n",
        "    list_of_events.sort(key=lambda x: x.timestamp)\n",
        "    all_shared_nodes = {}\n",
        "    for event in list_of_events:\n",
        "      for trx in event.transactions:\n",
        "        if ('type' in trx.payload) and (trx.payload['type'] == 'shard_model'):\n",
        "          all_shared_nodes[trx.payload['creator_address']] = True\n",
        "    print(address + ' ' + str(len(all_shared_nodes)))\n",
        "    if len(all_shared_nodes) == math.ceil(AGGREGATOR_COUNT * (NODE_COUNT / SHARD_SIZE)):\n",
        "      break\n",
        "  ledger.shard_models_all_ready()\n",
        "\n",
        "def check_for_all_local_models(address: str, ledger: DLedger):\n",
        "  with print_lock:\n",
        "    print(\"checking for other local models as \" + address + \"\\n\")\n",
        "  while True:\n",
        "    time.sleep(1)\n",
        "    list_of_events = list(ledger.node.events.values())\n",
        "    list_of_events.sort(key=lambda x: x.timestamp)\n",
        "    all_shared_nodes = {}\n",
        "    for event in list_of_events:\n",
        "      for trx in event.transactions:\n",
        "        if ('type' in trx.payload) and (trx.payload['type'] == 'local_model'):\n",
        "          all_shared_nodes[trx.payload['creator_address']] = True\n",
        "    if len(all_shared_nodes) == NODE_COUNT:\n",
        "      break\n",
        "  ledger.local_models_all_ready()\n",
        "\n",
        "def check_for_all_shares(address: str, ledger: DLedger):\n",
        "  with print_lock:\n",
        "    print(\"checking for other shares as \" + address + \"\\n\")\n",
        "  while True:\n",
        "    time.sleep(1)\n",
        "    list_of_events = list(ledger.node.events.values())\n",
        "    list_of_events.sort(key=lambda x: x.timestamp)\n",
        "    all_shared_nodes = {}\n",
        "    for event in list_of_events:\n",
        "      for trx in event.transactions:\n",
        "        if ('type' in trx.payload) and (trx.payload['type'] == 'initial_model_share'):\n",
        "          all_shared_nodes[trx.payload['creator_address']] = True\n",
        "    if len(all_shared_nodes) == NODE_COUNT:\n",
        "      break\n",
        "  for event in list_of_events:\n",
        "    for trx in event.transactions:\n",
        "      if ('type' in trx.payload) and (trx.payload['type'] == 'initial_model_share'):\n",
        "        ledger.node.learner.commit_other_initial_shares(trx.payload['creator_address'], trx.payload['weights'])\n",
        "  ledger.node.learner.prepare_initial_model(ledger.node.shared_order)\n",
        "  ledger.global_model_ready()\n",
        "\n",
        "def create_evaluation_string(node: HgNode, rpc_calls_so_far: int, start_of_gossip: float) -> str:\n",
        "    # How long have I been gossipping\n",
        "    gossip_duration = time.time() - start_of_gossip\n",
        "\n",
        "    # What is the average latency among them\n",
        "    latency_total = sum(event.latency for event in node.consensus_events)\n",
        "    latency_avg = (latency_total / len(node.consensus_events)) if node.consensus_events else 0\n",
        "\n",
        "    # How many events are there in total\n",
        "    num_events = sum(len(events) for events in node.hashgraph.values())\n",
        "\n",
        "    eval_str = (\n",
        "        \"\\n#### EVAL ####\"\n",
        "        f\"\\n\\tGossip Runtime: {gossip_duration:.5f} (sec)\"\n",
        "        f\"\\n\\tGossip Count: {rpc_calls_so_far}\"\n",
        "        f\"\\n\\tAvg. Gossip/sec: {rpc_calls_so_far / gossip_duration if gossip_duration > 0 else 0:.5f}\"\n",
        "        f\"\\n\\tAvg. Latency: {latency_avg:.5f} (sec)\"\n",
        "        f\"\\n\\tNum. of Events: {num_events}\"\n",
        "        f\"\\n\\tNum. of Consensus Events: {len(node.consensus_events)}\"\n",
        "        \"\\n#### EVAL ####\\n\"\n",
        "    )\n",
        "    return eval_str\n",
        "\n",
        "def gossip_routine(node: HgNode, peer_addresses: List[str]):\n",
        "\n",
        "    peer_client_map = {}\n",
        "    for addr in peer_addresses:\n",
        "        peer_client_map[addr] = xmlrpc.client.ServerProxy(f\"http://{addr}\", allow_none=True)\n",
        "\n",
        "    def close_connections():\n",
        "        for client in peer_client_map.values():\n",
        "            try:\n",
        "                client.close()\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    try:\n",
        "        c = 0\n",
        "        start_of_gossip = time.time()\n",
        "        event_evaluation_milestone_reached = False\n",
        "        while True:\n",
        "            # Choose a peer\n",
        "            random_peer_addr = random.choice(peer_addresses)\n",
        "            random_peer_connection = peer_client_map.get(random_peer_addr)\n",
        "            if not random_peer_connection:\n",
        "                continue\n",
        "\n",
        "            # Calculate how many events I know\n",
        "            known_event_nums = {addr: len(events) for addr, events in node.hashgraph.items()}\n",
        "\n",
        "            if EVALUATION_MODE:\n",
        "                num_events = sum(known_event_nums.values())\n",
        "                if num_events >= 5000 and not event_evaluation_milestone_reached:\n",
        "                    event_evaluation_milestone_reached = True\n",
        "                    eval_string = create_evaluation_string(node, c, start_of_gossip)\n",
        "                    with print_lock:\n",
        "                        print(eval_string)\n",
        "\n",
        "            # Ask the chosen peer how many events they do not know but I know\n",
        "            try:\n",
        "                num_events_to_send = nodes[random_peer_addr].node.get_number_of_missing_events(known_event_nums)\n",
        "            except Exception as e:\n",
        "                handle_error(e)\n",
        "                continue\n",
        "\n",
        "            any_event = False\n",
        "            for addr, num_missing in num_events_to_send.items():\n",
        "              if num_missing > 0:\n",
        "                any_event = True\n",
        "                break\n",
        "\n",
        "            # Send the missing events\n",
        "            missing_events = {}\n",
        "            for addr, num_missing in num_events_to_send.items():\n",
        "                if num_missing > 0:\n",
        "                    total_num_events = known_event_nums.get(addr, 0)\n",
        "                    start_index = total_num_events - num_missing\n",
        "                    missing_events[addr] = node.hashgraph[addr][start_index:]\n",
        "\n",
        "            # Wrap the missing events in a struct for RPC, attach my own address here\n",
        "            sync_events_dto = SyncEventsDTO(\n",
        "                sender_address=node.address,\n",
        "                missing_events=missing_events\n",
        "            )\n",
        "\n",
        "            if EVALUATION_MODE and c % PRINT_PER_MRPC_CALL == 0:\n",
        "                eval_string = create_evaluation_string(node, c, start_of_gossip)\n",
        "                if any_event:\n",
        "                    with print_lock:\n",
        "                        print(eval_string)\n",
        "\n",
        "            # Sync all events\n",
        "            try:\n",
        "                nodes[random_peer_addr].node.sync_all_events(sync_events_dto)\n",
        "            except Exception as e:\n",
        "                handle_error(e)\n",
        "                continue\n",
        "\n",
        "            c += 1\n",
        "            time.sleep(GOSSIP_WAIT_TIME)\n",
        "    finally:\n",
        "        close_connections()\n",
        "\n",
        "def read_peer_addresses(path: str, local_ip_addr: str) -> Dict[str, str]:\n",
        "    peers = {}\n",
        "    try:\n",
        "        with open(path, 'r') as file:\n",
        "            for line in file:\n",
        "                addr_name = line.strip().split(\" \")\n",
        "                addr = addr_name[0].replace(\"localhost\", local_ip_addr, 1)\n",
        "                peers[addr] = addr_name[1]\n",
        "    except Exception as e:\n",
        "        handle_error(e)\n",
        "    return peers\n",
        "\n",
        "def listen_for_rpc_connections(server: xmlrpc.server.SimpleXMLRPCServer):\n",
        "    server.serve_forever()\n",
        "\n",
        "def get_local_address() -> str:\n",
        "    try:\n",
        "        with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:\n",
        "            # This doesn't have to be reachable\n",
        "            s.connect((\"8.8.8.8\", 80))\n",
        "            return s.getsockname()[0]\n",
        "    except Exception as e:\n",
        "        handle_error(e)\n",
        "\n",
        "def handle_error(e: Exception):\n",
        "    if e is not None:\n",
        "        raise e\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FGNiuPCmKjH"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "file_url = 'https://www.kaggle.com/api/v1/datasets/download/uciml/human-activity-recognition-with-smartphones'\n",
        "\n",
        "r = requests.get(file_url, stream = True)\n",
        "\n",
        "with open(\"/content/ds.zip\", \"wb\") as file:\n",
        "    for block in r.iter_content(chunk_size = 1024):\n",
        "         if block:\n",
        "             file.write(block)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTdw6g82mW4p",
        "outputId": "161258a5-ac2d-4ccd-9bbd-742cd6432c80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/ds.zip\n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/ds.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbTJF-QBmeSU"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Step 1: Read data from Excel file\n",
        "csv_file_path = \"/content/train.csv\"\n",
        "test_csv_file_path = \"/content/test.csv\"\n",
        "\n",
        "data = pd.read_csv(csv_file_path)\n",
        "test_data = pd.read_csv(test_csv_file_path)\n",
        "\n",
        "\n",
        "#  Convert activities to numeric values\n",
        "activity_mapping = {\n",
        "    'WALKING': 1,\n",
        "    'WALKING_UPSTAIRS': 2,\n",
        "    'WALKING_DOWNSTAIRS': 3,\n",
        "    'SITTING': 4,\n",
        "    'STANDING': 5,\n",
        "    'LAYING': 6\n",
        "}\n",
        "\n",
        "data['Activity_numeric'] = data['Activity'].map(activity_mapping)\n",
        "test_data['Activity_numeric'] = test_data['Activity'].map(activity_mapping)\n",
        "\n",
        "# central database\n",
        "data_central = data[data['subject'] < 26]\n",
        "# Dictionary to store separate databases\n",
        "databases = {}\n",
        "\n",
        "# Filter rows where subject number is between 26 and 30\n",
        "for subject_number in range(26, 31):\n",
        "    databases[subject_number] = data[data['subject'] == subject_number]\n",
        "\n",
        "def preprocess_data(dataset, num_classes):\n",
        "    # Assuming the dataset is a pandas DataFrame\n",
        "    X = dataset.drop(columns=['Activity', 'Activity_numeric']).to_numpy()\n",
        "    X_train = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "    y = dataset['Activity_numeric'].to_numpy()\n",
        "    y_one_hot = to_categorical(y - 1, num_classes=num_classes)  # y - 1 to convert labels from 1-6 to 0-5\n",
        "    return X_train, y_one_hot\n",
        "\n",
        "# Central data\n",
        "X, y_one_hot = preprocess_data(data_central, num_classes=6)\n",
        "# Test data\n",
        "test_X, test_y_one_hot = preprocess_data(test_data, num_classes=6)\n",
        "\n",
        "# Federated data\n",
        "preprocessed_federated_data = {}  # Dictionary to store preprocessed data\n",
        "\n",
        "for dataset_index in range(26, 31):\n",
        "    temp_X, temp_y_one_hot = preprocess_data(databases[dataset_index], num_classes=6)\n",
        "\n",
        "    # Initialize KFold\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    fold_index = 0\n",
        "    for train_index, valid_index in kf.split(temp_X):\n",
        "        X_train, X_valid = temp_X[train_index], temp_X[valid_index]\n",
        "        y_train, y_valid = temp_y_one_hot[train_index], temp_y_one_hot[valid_index]\n",
        "\n",
        "        preprocessed_federated_data[f'{dataset_index}_fold_{fold_index}'] = {\n",
        "            'X_train': X_train,\n",
        "            'X_valid': X_valid,\n",
        "            'y_train': y_train,\n",
        "            'y_valid': y_valid\n",
        "        }\n",
        "        fold_index += 1\n",
        "\n",
        "# Now preprocessed_federated_data contains the 5-fold splits for each dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtViiGMYmpAD"
      },
      "outputs": [],
      "source": [
        "feature_shape = X.shape[1]\n",
        "classes = 6\n",
        "lr =0.01\n",
        "\n",
        "# Define your custom central model architecture\n",
        "def build_model(feature_shape, classes=6):\n",
        "    # Define the model\n",
        "    model = Sequential()\n",
        "    # Convolutional layers\n",
        "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(feature_shape)))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    # Flatten layer\n",
        "    model.add(Flatten())\n",
        "    # Fully connected layers\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    # Output layer\n",
        "    model.add(Dense(classes, activation='softmax')) # num_classes should be adjusted based on your classification task\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=tf.keras.optimizers.SGD(lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykjmKqn6WCqo"
      },
      "outputs": [],
      "source": [
        "def main(index, name, port):\n",
        "\n",
        "    with print_lock:\n",
        "        print(name)\n",
        "\n",
        "    model_arch = build_model(X.shape[1:],classes)\n",
        "\n",
        "    client_id = FIRST_CLIENT + index\n",
        "\n",
        "    print(list(preprocessed_federated_data.keys()))\n",
        "\n",
        "    x_local, y_local =   preprocessed_federated_data[f'{client_id}_fold_{FOLD_INDEX}']['X_train'], preprocessed_federated_data[f'{client_id}_fold_{FOLD_INDEX}']['y_train']\n",
        "    x_local_valid, y_local_valid =  preprocessed_federated_data[f'{client_id}_fold_{FOLD_INDEX}']['X_valid'], preprocessed_federated_data[f'{client_id}_fold_{FOLD_INDEX}']['y_valid']\n",
        "\n",
        "    distributed_ledger = DLedger.new_dledger(port, \"peers.txt\", [x_local, y_local, x_local_valid, y_local_valid], model_arch)\n",
        "    nodes[distributed_ledger.my_address] = distributed_ledger\n",
        "\n",
        "    distributed_ledger.wait_for_peers()\n",
        "    with print_lock:\n",
        "        print(f\"I am online at {distributed_ledger.my_address} and all peers are available.\")\n",
        "\n",
        "    distributed_ledger.start()\n",
        "\n",
        "    def on_sharing_initial_model_election_done():\n",
        "      with print_lock:\n",
        "        print(\"initialization election is finished\\n\")\n",
        "      distributed_ledger.global_model_ready = on_initial_global_model_ready\n",
        "      distributed_ledger.share_initial_weights()\n",
        "\n",
        "    def on_initial_global_model_ready():\n",
        "      with print_lock:\n",
        "        print(\"training global model as \" + distributed_ledger.my_address + \"\\n\")\n",
        "      distributed_ledger.node.learner.initial_train(X, y_one_hot)\n",
        "      distributed_ledger.node.learner.train()\n",
        "      loss, accuracy = distributed_ledger.node.learner.model_arch.evaluate(test_X, test_y_one_hot)\n",
        "      with print_lock:\n",
        "        print(\"trained local model is ready as \" + distributed_ledger.my_address + \"\\n\")\n",
        "      distributed_ledger.local_models_all_ready = on_all_local_models_ready\n",
        "      distributed_ledger.local_model_to_hashgraph()\n",
        "\n",
        "    def on_all_local_models_ready():\n",
        "      with print_lock:\n",
        "        print(\"all local models are ready on the hashgraph\\n\")\n",
        "      distributed_ledger.on_election_done = on_sharding_election_done\n",
        "      distributed_ledger.start_election()\n",
        "\n",
        "    def on_sharding_election_done():\n",
        "      with print_lock:\n",
        "        print(\"sharding election is finished\\n\")\n",
        "      distributed_ledger.find_my_shard()\n",
        "      with print_lock:\n",
        "        print(\"shard of \" + distributed_ledger.my_address + \" is \" + str(distributed_ledger.shard) + \"\\n\")\n",
        "      distributed_ledger.shard_models_all_ready = on_all_shard_models_ready\n",
        "      distributed_ledger.check_and_start_shard_aggregation()\n",
        "\n",
        "    def on_all_shard_models_ready():\n",
        "      with print_lock:\n",
        "        print(\"aggregation done on aggregator as \" + distributed_ledger.my_address + \"\\n\")\n",
        "        print(\"starting next election for global aggregators\\n\")\n",
        "      distributed_ledger.on_election_done = on_globalling_election_done\n",
        "      distributed_ledger.start_election()\n",
        "\n",
        "    def on_globalling_election_done():\n",
        "      with print_lock:\n",
        "        print(\"globalling election is finished\\n\")\n",
        "        print(distributed_ledger.node.shared_order)\n",
        "      distributed_ledger.global_models_all_ready = on_all_global_models_ready\n",
        "      distributed_ledger.check_and_start_global_aggregation()\n",
        "      with print_lock:\n",
        "        print(\"global aggregation done on global aggregator as \" + distributed_ledger.my_address + \"\\n\")\n",
        "\n",
        "    def on_all_global_models_ready():\n",
        "      with print_lock:\n",
        "        print(\"all global models are ready on hashgraph\\n\")\n",
        "      distributed_ledger.aggerate_my_final_model()\n",
        "      with print_lock:\n",
        "        print(\"final global model is ready\\n\")\n",
        "      distributed_ledger.node.learner.prepare_for_transfer()\n",
        "      distributed_ledger.node.learner.train()\n",
        "      loss, accuracy = distributed_ledger.node.learner.model_arch.evaluate(test_X, test_y_one_hot)\n",
        "      print( distributed_ledger.my_address + ', accuracy: '  + str(accuracy))\n",
        "\n",
        "    distributed_ledger.on_election_done = on_sharing_initial_model_election_done\n",
        "    distributed_ledger.start_election()\n",
        "\n",
        "    def print_global_models():\n",
        "      while True:\n",
        "        time.sleep(5)\n",
        "        with print_lock:\n",
        "          for event in distributed_ledger.node.events.values():\n",
        "            for trx in event.transactions:\n",
        "              if ('type' in trx.payload) and (trx.payload['type'] == 'global_model'):\n",
        "                print(trx.payload['weights'])\n",
        "\n",
        "    def print_periodically():\n",
        "      while True:\n",
        "        time.sleep(5)\n",
        "        with print_lock:\n",
        "          print(\"transactions in \" + distributed_ledger.my_address + \": -----------------------------\\n\")\n",
        "          for k, v in distributed_ledger.node.events.items():\n",
        "            print(k + ' ' + str(v.timestamp) + ' ' + json.dumps(list(map(lambda b: b.payload, v.transactions))))\n",
        "          print(\"------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "    # threading.Thread(target=print_global_models).start()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxWJJ084ZYCG",
        "outputId": "17e547ab-5dd7-40c5-85c9-3aac099adb1e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172.28.0.12:8081\n",
            "172.28.0.12:8082\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172.28.0.12:8083\n",
            "172.28.0.12:8084\n",
            "172.28.0.12:8085\n",
            "['26_fold_0', '26_fold_1', '26_fold_2', '26_fold_3', '26_fold_4', '27_fold_0', '27_fold_1', '27_fold_2', '27_fold_3', '27_fold_4', '28_fold_0', '28_fold_1', '28_fold_2', '28_fold_3', '28_fold_4', '29_fold_0', '29_fold_1', '29_fold_2', '29_fold_3', '29_fold_4', '30_fold_0', '30_fold_1', '30_fold_2', '30_fold_3', '30_fold_4']\n",
            "['26_fold_0', '26_fold_1', '26_fold_2', '26_fold_3', '26_fold_4', '27_fold_0', '27_fold_1', '27_fold_2', '27_fold_3', '27_fold_4', '28_fold_0', '28_fold_1', '28_fold_2', '28_fold_3', '28_fold_4', '29_fold_0', '29_fold_1', '29_fold_2', '29_fold_3', '29_fold_4', '30_fold_0', '30_fold_1', '30_fold_2', '30_fold_3', '30_fold_4']\n",
            "['26_fold_0', '26_fold_1', '26_fold_2', '26_fold_3', '26_fold_4', '27_fold_0', '27_fold_1', '27_fold_2', '27_fold_3', '27_fold_4', '28_fold_0', '28_fold_1', '28_fold_2', '28_fold_3', '28_fold_4', '29_fold_0', '29_fold_1', '29_fold_2', '29_fold_3', '29_fold_4', '30_fold_0', '30_fold_1', '30_fold_2', '30_fold_3', '30_fold_4']\n",
            "['26_fold_0', '26_fold_1', '26_fold_2', '26_fold_3', '26_fold_4', '27_fold_0', '27_fold_1', '27_fold_2', '27_fold_3', '27_fold_4', '28_fold_0', '28_fold_1', '28_fold_2', '28_fold_3', '28_fold_4', '29_fold_0', '29_fold_1', '29_fold_2', '29_fold_3', '29_fold_4', '30_fold_0', '30_fold_1', '30_fold_2', '30_fold_3', '30_fold_4']\n",
            "waiting...\n",
            "\n",
            "[Errno 111] Connection refused\n",
            "['26_fold_0', '26_fold_1', '26_fold_2', '26_fold_3', '26_fold_4', '27_fold_0', '27_fold_1', '27_fold_2', '27_fold_3', '27_fold_4', '28_fold_0', '28_fold_1', '28_fold_2', '28_fold_3', '28_fold_4', '29_fold_0', '29_fold_1', '29_fold_2', '29_fold_3', '29_fold_4', '30_fold_0', '30_fold_1', '30_fold_2', '30_fold_3', '30_fold_4']\n",
            "waiting...\n",
            "\n",
            "waiting...\n",
            "\n",
            "waiting...\n",
            "\n",
            "waiting...\n",
            "\n",
            "I am online at 172.28.0.12:8085 and all peers are available.\n",
            "I am online at 172.28.0.12:8083 and all peers are available.\n",
            "\n",
            "#### EVAL ####\n",
            "\tGossip Runtime: 0.00004 (sec)\n",
            "\tGossip Count: 0\n",
            "\tAvg. Gossip/sec: 0.00000\n",
            "\tAvg. Latency: 0.00000 (sec)\n",
            "\tNum. of Events: 1\n",
            "\tNum. of Consensus Events: 0\n",
            "#### EVAL ####\n",
            "\n",
            "election started\n",
            "\n",
            "#### EVAL ####\n",
            "\tGossip Runtime: 0.00003 (sec)\n",
            "\tGossip Count: 0\n",
            "\tAvg. Gossip/sec: 0.00000\n",
            "\tAvg. Latency: 0.00000 (sec)\n",
            "\tNum. of Events: 1\n",
            "\tNum. of Consensus Events: 0\n",
            "#### EVAL ####\n",
            "\n",
            "I am online at 172.28.0.12:8081 and all peers are available.\n",
            "I am online at 172.28.0.12:8082 and all peers are available.\n",
            "election started\n",
            "\n",
            "#### EVAL ####\n",
            "\tGossip Runtime: 0.00002 (sec)\n",
            "\tGossip Count: 0\n",
            "\tAvg. Gossip/sec: 0.00000\n",
            "\tAvg. Latency: 0.00000 (sec)\n",
            "\tNum. of Events: 2\n",
            "\tNum. of Consensus Events: 0\n",
            "#### EVAL ####\n",
            "\n",
            "election started\n",
            "\n",
            "#### EVAL ####\n",
            "\tGossip Runtime: 0.00002 (sec)\n",
            "\tGossip Count: 0\n",
            "\tAvg. Gossip/sec: 0.00000\n",
            "\tAvg. Latency: 0.00000 (sec)\n",
            "\tNum. of Events: 1\n",
            "\tNum. of Consensus Events: 0\n",
            "#### EVAL ####\n",
            "\n",
            "election started\n",
            "I am online at 172.28.0.12:8084 and all peers are available.\n",
            "\n",
            "#### EVAL ####\n",
            "\tGossip Runtime: 0.00002 (sec)\n",
            "\tGossip Count: 0\n",
            "\tAvg. Gossip/sec: 0.00000\n",
            "\tAvg. Latency: 0.00000 (sec)\n",
            "\tNum. of Events: 3\n",
            "\tNum. of Consensus Events: 0\n",
            "#### EVAL ####\n",
            "\n",
            "election started\n",
            "initialization election is finished\n",
            "\n",
            "checking for other shares as 172.28.0.12:8081\n",
            "\n",
            "initialization election is finished\n",
            "\n",
            "checking for other shares as 172.28.0.12:8082\n",
            "\n",
            "initialization election is finished\n",
            "\n",
            "checking for other shares as 172.28.0.12:8083\n",
            "\n",
            "initialization election is finished\n",
            "\n",
            "checking for other shares as 172.28.0.12:8085\n",
            "\n",
            "initialization election is finished\n",
            "\n",
            "checking for other shares as 172.28.0.12:8084\n",
            "\n",
            "training global model as 172.28.0.12:8083\n",
            "\n",
            "training global model as 172.28.0.12:8081\n",
            "\n",
            "training global model as 172.28.0.12:8082\n",
            "\n",
            "training global model as 172.28.0.12:8085\n",
            "\n",
            "training global model as 172.28.0.12:8084\n",
            "\n",
            "Epoch 1/80\n",
            "Epoch 1/80\n",
            "Epoch 1/80\n",
            "Epoch 1/80\n",
            "Epoch 1/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 212ms/step - accuracy: 0.2899 - loss: 1.7493 - val_accuracy: 0.4236 - val_loss: 1.5651\n",
            "Epoch 2/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 212ms/step - accuracy: 0.2981 - loss: 1.7499 - val_accuracy: 0.3427 - val_loss: 1.5746\n",
            "Epoch 2/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 247ms/step - accuracy: 0.2921 - loss: 1.7480 - val_accuracy: 0.3561 - val_loss: 1.5680\n",
            "Epoch 2/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 267ms/step - accuracy: 0.3067 - loss: 1.7494 - val_accuracy: 0.4224 - val_loss: 1.5616\n",
            "Epoch 2/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4321 - loss: 1.4849 - val_accuracy: 0.5052 - val_loss: 1.2479\n",
            "\u001b[1m 5/60\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4579 - loss: 1.5493Epoch 3/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.4333 - loss: 1.4819 - val_accuracy: 0.5770 - val_loss: 1.2424\n",
            "Epoch 3/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.4179 - loss: 1.4806 - val_accuracy: 0.3883 - val_loss: 1.2577\n",
            "Epoch 3/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 223ms/step - accuracy: 0.3145 - loss: 1.7491 - val_accuracy: 0.3816 - val_loss: 1.5730\n",
            "Epoch 2/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.5155 - loss: 1.1737 - val_accuracy: 0.7279 - val_loss: 1.0419\n",
            "\u001b[1m53/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5224 - loss: 1.1735Epoch 4/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.5270 - loss: 1.1658 - val_accuracy: 0.6123 - val_loss: 1.0561\n",
            "Epoch 4/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.4984 - loss: 1.1708 - val_accuracy: 0.5746 - val_loss: 1.0532\n",
            "Epoch 4/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.6280 - loss: 0.9950 - val_accuracy: 0.4321 - val_loss: 1.0076\n",
            "\u001b[1m45/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5892 - loss: 1.0016Epoch 5/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5935 - loss: 0.9935 - val_accuracy: 0.4863 - val_loss: 0.9643\n",
            "Epoch 5/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.6309 - loss: 0.8872 - val_accuracy: 0.6525 - val_loss: 0.8535\n",
            "Epoch 6/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.5835 - loss: 1.0037 - val_accuracy: 0.6896 - val_loss: 0.9440\n",
            "Epoch 5/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.6166 - loss: 0.8899 - val_accuracy: 0.4528 - val_loss: 0.9385\n",
            "Epoch 6/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.4093 - loss: 1.4959 - val_accuracy: 0.5393 - val_loss: 1.2480\n",
            "Epoch 3/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.4308 - loss: 1.4930 - val_accuracy: 0.4291 - val_loss: 1.2538\n",
            "Epoch 3/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5245 - loss: 1.1796 - val_accuracy: 0.5283 - val_loss: 1.0538\n",
            "Epoch 4/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5090 - loss: 1.1768 - val_accuracy: 0.7054 - val_loss: 1.0450\n",
            "Epoch 4/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.6491 - loss: 0.8008 - val_accuracy: 0.6525 - val_loss: 0.7920\n",
            "Epoch 7/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.6576 - loss: 0.8068 - val_accuracy: 0.5861 - val_loss: 0.8496\n",
            "Epoch 7/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.6706 - loss: 0.8869 - val_accuracy: 0.7413 - val_loss: 0.8503\n",
            "Epoch 6/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.6188 - loss: 0.9891 - val_accuracy: 0.6342 - val_loss: 0.9469\n",
            "Epoch 5/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.5924 - loss: 1.0019 - val_accuracy: 0.6415 - val_loss: 0.9469\n",
            "Epoch 5/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.6887 - loss: 0.7198 - val_accuracy: 0.6823 - val_loss: 0.7812\n",
            "Epoch 8/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.7278 - loss: 0.7195 - val_accuracy: 0.7042 - val_loss: 0.7464\n",
            "\u001b[1m26/60\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6804 - loss: 0.7955Epoch 8/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.6540 - loss: 0.8880 - val_accuracy: 0.7206 - val_loss: 0.8451\n",
            "Epoch 6/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6683 - loss: 0.8028 - val_accuracy: 0.7127 - val_loss: 0.7675\n",
            "Epoch 7/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.7780 - loss: 0.6197 - val_accuracy: 0.7365 - val_loss: 0.6132\n",
            "Epoch 9/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6861 - loss: 0.8740 - val_accuracy: 0.4680 - val_loss: 0.9460\n",
            "\u001b[1m18/60\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7633 - loss: 0.7042Epoch 6/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.7498 - loss: 0.6221 - val_accuracy: 0.8168 - val_loss: 0.5999\n",
            "\u001b[1m35/60\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7518 - loss: 0.6957Epoch 9/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.6756 - loss: 0.7921 - val_accuracy: 0.7322 - val_loss: 0.7526\n",
            "Epoch 7/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7355 - loss: 0.6980 - val_accuracy: 0.7225 - val_loss: 0.7248\n",
            "Epoch 8/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.7582 - loss: 0.5700 - val_accuracy: 0.7279 - val_loss: 0.6113\n",
            "Epoch 10/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.6862 - loss: 0.7841 - val_accuracy: 0.6482 - val_loss: 0.8104\n",
            "Epoch 7/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7621 - loss: 0.5846 - val_accuracy: 0.7882 - val_loss: 0.5499\n",
            "Epoch 10/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.6942 - loss: 0.7184 - val_accuracy: 0.6774 - val_loss: 0.7390\n",
            "Epoch 8/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6891 - loss: 0.7201 - val_accuracy: 0.5892 - val_loss: 0.8112\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.7274 - loss: 0.6786 - val_accuracy: 0.8077 - val_loss: 0.6281\n",
            "Epoch 8/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8135 - loss: 0.4740 - val_accuracy: 0.7365 - val_loss: 0.5389\n",
            "Epoch 9/80\n",
            "Epoch 11/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.7191 - loss: 0.6729 - val_accuracy: 0.7900 - val_loss: 0.6093\n",
            "Epoch 9/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.7288 - loss: 0.6464 - val_accuracy: 0.6896 - val_loss: 0.6867\n",
            "Epoch 9/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.7802 - loss: 0.5598 - val_accuracy: 0.6975 - val_loss: 0.6588\n",
            "Epoch 10/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8091 - loss: 0.4705 - val_accuracy: 0.8363 - val_loss: 0.5103\n",
            "Epoch 11/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7412 - loss: 0.5902 - val_accuracy: 0.8052 - val_loss: 0.5363\n",
            "Epoch 10/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8028 - loss: 0.4718 - val_accuracy: 0.6896 - val_loss: 0.6224\n",
            "Epoch 12/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.7744 - loss: 0.5740 - val_accuracy: 0.6999 - val_loss: 0.6512\n",
            "Epoch 10/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.8096 - loss: 0.4653 - val_accuracy: 0.8369 - val_loss: 0.4604\n",
            "Epoch 12/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.7777 - loss: 0.5337 - val_accuracy: 0.7273 - val_loss: 0.5651\n",
            "Epoch 11/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8039 - loss: 0.4831 - val_accuracy: 0.8028 - val_loss: 0.5423\n",
            "Epoch 11/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8610 - loss: 0.3641 - val_accuracy: 0.7018 - val_loss: 0.8571\n",
            "\u001b[1m35/60\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8405 - loss: 0.4134Epoch 13/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7982 - loss: 0.4958 - val_accuracy: 0.8040 - val_loss: 0.5107\n",
            "Epoch 11/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8578 - loss: 0.3706 - val_accuracy: 0.8071 - val_loss: 0.5177\n",
            "\u001b[1m24/60\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8232 - loss: 0.4259Epoch 13/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8278 - loss: 0.4285 - val_accuracy: 0.7638 - val_loss: 0.4938\n",
            "\u001b[1m53/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8523 - loss: 0.3826Epoch 12/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8425 - loss: 0.4097 - val_accuracy: 0.6762 - val_loss: 0.6908\n",
            "Epoch 12/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8549 - loss: 0.3772 - val_accuracy: 0.8095 - val_loss: 0.5009\n",
            "Epoch 14/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8246 - loss: 0.4264 - val_accuracy: 0.8101 - val_loss: 0.4799\n",
            "Epoch 12/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8570 - loss: 0.3385 - val_accuracy: 0.8235 - val_loss: 0.4655\n",
            "Epoch 14/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8394 - loss: 0.3992 - val_accuracy: 0.7389 - val_loss: 0.5175\n",
            "Epoch 13/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.8599 - loss: 0.3614 - val_accuracy: 0.7973 - val_loss: 0.4926\n",
            "\u001b[1m47/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8638 - loss: 0.3317Epoch 13/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8628 - loss: 0.3310 - val_accuracy: 0.7578 - val_loss: 0.5441\n",
            "Epoch 15/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8465 - loss: 0.3999 - val_accuracy: 0.8290 - val_loss: 0.4733\n",
            "\u001b[1m43/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8812 - loss: 0.3294Epoch 13/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.8295 - loss: 0.4119 - val_accuracy: 0.7389 - val_loss: 0.5892\n",
            "\u001b[1m10/60\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7908 - loss: 0.4195Epoch 14/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.8698 - loss: 0.3205 - val_accuracy: 0.8472 - val_loss: 0.4077\n",
            "Epoch 15/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8793 - loss: 0.3308 - val_accuracy: 0.8369 - val_loss: 0.4372\n",
            "Epoch 14/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.8508 - loss: 0.3333 - val_accuracy: 0.7754 - val_loss: 0.4629\n",
            "Epoch 16/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.8761 - loss: 0.3339 - val_accuracy: 0.8302 - val_loss: 0.4611\n",
            "Epoch 14/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.8641 - loss: 0.3175 - val_accuracy: 0.8399 - val_loss: 0.4600\n",
            "Epoch 15/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8756 - loss: 0.2942 - val_accuracy: 0.7912 - val_loss: 0.5329\n",
            "Epoch 16/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8821 - loss: 0.3076 - val_accuracy: 0.8472 - val_loss: 0.4426\n",
            "Epoch 15/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8865 - loss: 0.2732 - val_accuracy: 0.8168 - val_loss: 0.4851\n",
            "Epoch 17/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8822 - loss: 0.2771 - val_accuracy: 0.8052 - val_loss: 0.4541\n",
            "Epoch 18/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9055 - loss: 0.2465 - val_accuracy: 0.8308 - val_loss: 0.4132\n",
            "Epoch 19/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8896 - loss: 0.2852 - val_accuracy: 0.8156 - val_loss: 0.5139\n",
            "\u001b[1m15/60\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8483 - loss: 0.3537Epoch 16/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.8585 - loss: 0.3376 - val_accuracy: 0.8180 - val_loss: 0.4555\n",
            "Epoch 15/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8808 - loss: 0.2892 - val_accuracy: 0.7231 - val_loss: 0.6690\n",
            "Epoch 16/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8972 - loss: 0.2450 - val_accuracy: 0.7876 - val_loss: 0.4915\n",
            "Epoch 20/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.8667 - loss: 0.3206 - val_accuracy: 0.8259 - val_loss: 0.4574\n",
            "\u001b[1m 1/60\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08\u001b[0m 1s/step - accuracy: 0.9062 - loss: 0.2307Epoch 17/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8840 - loss: 0.2834 - val_accuracy: 0.7827 - val_loss: 0.4977\n",
            "Epoch 17/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.8849 - loss: 0.2794 - val_accuracy: 0.8211 - val_loss: 0.5436\n",
            "Epoch 17/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8851 - loss: 0.2682 - val_accuracy: 0.7955 - val_loss: 0.4799\n",
            "Epoch 18/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.8870 - loss: 0.2925 - val_accuracy: 0.8430 - val_loss: 0.4547\n",
            "Epoch 16/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.8862 - loss: 0.2563 - val_accuracy: 0.8466 - val_loss: 0.3865\n",
            "Epoch 21/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8916 - loss: 0.2639 - val_accuracy: 0.8539 - val_loss: 0.4396\n",
            "Epoch 18/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8934 - loss: 0.2594 - val_accuracy: 0.8418 - val_loss: 0.4113\n",
            "Epoch 18/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.8921 - loss: 0.2595 - val_accuracy: 0.8016 - val_loss: 0.4875\n",
            "\u001b[1m22/60\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9266 - loss: 0.1987Epoch 19/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8870 - loss: 0.2817 - val_accuracy: 0.8296 - val_loss: 0.4411\n",
            "Epoch 17/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8854 - loss: 0.2705 - val_accuracy: 0.8430 - val_loss: 0.4423\n",
            "Epoch 19/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8924 - loss: 0.2570 - val_accuracy: 0.8454 - val_loss: 0.4280\n",
            "Epoch 19/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9187 - loss: 0.2089 - val_accuracy: 0.8466 - val_loss: 0.4515\n",
            "Epoch 22/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9132 - loss: 0.2186 - val_accuracy: 0.8515 - val_loss: 0.4060\n",
            "Epoch 20/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9072 - loss: 0.2349 - val_accuracy: 0.7462 - val_loss: 0.6375\n",
            "Epoch 20/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.8705 - loss: 0.2850 - val_accuracy: 0.8363 - val_loss: 0.4312\n",
            "Epoch 18/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9023 - loss: 0.2380 - val_accuracy: 0.8478 - val_loss: 0.4123\n",
            "Epoch 20/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9217 - loss: 0.2109 - val_accuracy: 0.8539 - val_loss: 0.3955\n",
            "Epoch 21/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.9187 - loss: 0.2019 - val_accuracy: 0.8241 - val_loss: 0.4392\n",
            "\u001b[1m 2/60\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.8711 - loss: 0.2657 Epoch 23/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8936 - loss: 0.2548 - val_accuracy: 0.8253 - val_loss: 0.4847\n",
            "Epoch 21/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8731 - loss: 0.2860 - val_accuracy: 0.8052 - val_loss: 0.4797\n",
            "Epoch 19/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9064 - loss: 0.2256 - val_accuracy: 0.8509 - val_loss: 0.3741\n",
            "\u001b[1m45/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8953 - loss: 0.2449Epoch 21/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.8986 - loss: 0.2366 - val_accuracy: 0.8521 - val_loss: 0.4029\n",
            "Epoch 22/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8993 - loss: 0.2404 - val_accuracy: 0.8393 - val_loss: 0.4258\n",
            "Epoch 22/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9172 - loss: 0.1992 - val_accuracy: 0.8174 - val_loss: 0.4840\n",
            "Epoch 24/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9292 - loss: 0.1897 - val_accuracy: 0.8442 - val_loss: 0.4184\n",
            "Epoch 23/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9067 - loss: 0.2142 - val_accuracy: 0.8515 - val_loss: 0.3869\n",
            "Epoch 25/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9057 - loss: 0.2207 - val_accuracy: 0.8393 - val_loss: 0.4592\n",
            "Epoch 23/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9150 - loss: 0.2036 - val_accuracy: 0.8503 - val_loss: 0.3718\n",
            "Epoch 24/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9303 - loss: 0.1726 - val_accuracy: 0.8649 - val_loss: 0.4065\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9205 - loss: 0.2038 - val_accuracy: 0.8503 - val_loss: 0.3797\n",
            "Epoch 26/80\n",
            "Epoch 24/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9177 - loss: 0.2105 - val_accuracy: 0.8643 - val_loss: 0.3802\n",
            "Epoch 22/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9193 - loss: 0.2024 - val_accuracy: 0.8436 - val_loss: 0.4136\n",
            "Epoch 25/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9050 - loss: 0.2395 - val_accuracy: 0.7894 - val_loss: 0.5280\n",
            "Epoch 20/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9259 - loss: 0.1891 - val_accuracy: 0.8667 - val_loss: 0.3661\n",
            "\u001b[1m48/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9107 - loss: 0.2333Epoch 27/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9247 - loss: 0.1912 - val_accuracy: 0.8448 - val_loss: 0.3994\n",
            "Epoch 25/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9106 - loss: 0.2319 - val_accuracy: 0.8223 - val_loss: 0.4580\n",
            "Epoch 21/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9363 - loss: 0.1719 - val_accuracy: 0.8746 - val_loss: 0.3534\n",
            "Epoch 26/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9260 - loss: 0.2032 - val_accuracy: 0.8478 - val_loss: 0.4217\n",
            "Epoch 23/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9309 - loss: 0.1780 - val_accuracy: 0.8418 - val_loss: 0.4188\n",
            "Epoch 27/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9317 - loss: 0.1805 - val_accuracy: 0.8393 - val_loss: 0.4565\n",
            "Epoch 28/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9202 - loss: 0.2001 - val_accuracy: 0.8436 - val_loss: 0.4280\n",
            "Epoch 26/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9080 - loss: 0.2246 - val_accuracy: 0.8448 - val_loss: 0.4501\n",
            "Epoch 22/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9181 - loss: 0.2139 - val_accuracy: 0.8387 - val_loss: 0.4390\n",
            "Epoch 24/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9174 - loss: 0.1980 - val_accuracy: 0.8375 - val_loss: 0.4182\n",
            "Epoch 25/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.9292 - loss: 0.1857 - val_accuracy: 0.8764 - val_loss: 0.3522\n",
            "Epoch 27/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9376 - loss: 0.1722 - val_accuracy: 0.8241 - val_loss: 0.5083\n",
            "Epoch 28/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9141 - loss: 0.2215 - val_accuracy: 0.8618 - val_loss: 0.3587\n",
            "\u001b[1m41/60\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9235 - loss: 0.1977Epoch 23/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9389 - loss: 0.1660 - val_accuracy: 0.7985 - val_loss: 0.4764\n",
            "Epoch 29/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9243 - loss: 0.1954 - val_accuracy: 0.8588 - val_loss: 0.4015\n",
            "Epoch 26/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9221 - loss: 0.2056 - val_accuracy: 0.8387 - val_loss: 0.4571\n",
            "\u001b[1m36/60\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9058 - loss: 0.2208Epoch 24/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9112 - loss: 0.2094 - val_accuracy: 0.8497 - val_loss: 0.4369\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9319 - loss: 0.1786 - val_accuracy: 0.8801 - val_loss: 0.3477\n",
            "Epoch 30/80\n",
            "Epoch 27/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9274 - loss: 0.1745 - val_accuracy: 0.8649 - val_loss: 0.3799\n",
            "Epoch 28/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9291 - loss: 0.1715 - val_accuracy: 0.8673 - val_loss: 0.3859\n",
            "Epoch 28/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9345 - loss: 0.1591 - val_accuracy: 0.8685 - val_loss: 0.3829\n",
            "Epoch 29/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9221 - loss: 0.2051 - val_accuracy: 0.8509 - val_loss: 0.3992\n",
            "Epoch 25/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9431 - loss: 0.1510 - val_accuracy: 0.8819 - val_loss: 0.3797\n",
            "Epoch 31/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9341 - loss: 0.1727 - val_accuracy: 0.8655 - val_loss: 0.3743\n",
            "Epoch 29/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9417 - loss: 0.1565 - val_accuracy: 0.8698 - val_loss: 0.3700\n",
            "Epoch 29/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9330 - loss: 0.1642 - val_accuracy: 0.8497 - val_loss: 0.3997\n",
            "\u001b[1m38/60\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9280 - loss: 0.1731Epoch 30/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9247 - loss: 0.1872 - val_accuracy: 0.8089 - val_loss: 0.5475\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9318 - loss: 0.1689 - val_accuracy: 0.8649 - val_loss: 0.3433\n",
            "Epoch 30/80\n",
            "Epoch 26/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9483 - loss: 0.1466 - val_accuracy: 0.8746 - val_loss: 0.3531\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9488 - loss: 0.1392 - val_accuracy: 0.8734 - val_loss: 0.4005\n",
            "Epoch 32/80\n",
            "Epoch 30/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9408 - loss: 0.1575 - val_accuracy: 0.8874 - val_loss: 0.3573\n",
            "\u001b[1m41/60\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9335 - loss: 0.1642Epoch 31/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9371 - loss: 0.1803 - val_accuracy: 0.8582 - val_loss: 0.3854\n",
            "Epoch 27/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9351 - loss: 0.1626 - val_accuracy: 0.8716 - val_loss: 0.3664\n",
            "Epoch 31/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9463 - loss: 0.1363 - val_accuracy: 0.8752 - val_loss: 0.3682\n",
            "\u001b[1m45/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9364 - loss: 0.1588Epoch 33/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9356 - loss: 0.1734 - val_accuracy: 0.8649 - val_loss: 0.3500\n",
            "\u001b[1m10/60\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9497 - loss: 0.1289Epoch 31/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9365 - loss: 0.1581 - val_accuracy: 0.8831 - val_loss: 0.3595\n",
            "Epoch 32/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9248 - loss: 0.1841 - val_accuracy: 0.8223 - val_loss: 0.4870\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9476 - loss: 0.1305Epoch 28/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9518 - loss: 0.1364 - val_accuracy: 0.8734 - val_loss: 0.4219\n",
            "Epoch 32/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9476 - loss: 0.1306 - val_accuracy: 0.8691 - val_loss: 0.3785\n",
            "Epoch 32/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9367 - loss: 0.1458 - val_accuracy: 0.8436 - val_loss: 0.4652\n",
            "Epoch 34/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9445 - loss: 0.1499 - val_accuracy: 0.8095 - val_loss: 0.4650\n",
            "Epoch 33/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9474 - loss: 0.1412 - val_accuracy: 0.8527 - val_loss: 0.4384\n",
            "Epoch 33/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.9527 - loss: 0.1305 - val_accuracy: 0.8716 - val_loss: 0.3326\n",
            "Epoch 35/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9462 - loss: 0.1471 - val_accuracy: 0.8698 - val_loss: 0.3726\n",
            "Epoch 33/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9303 - loss: 0.1748 - val_accuracy: 0.8722 - val_loss: 0.3610\n",
            "Epoch 34/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9412 - loss: 0.1434 - val_accuracy: 0.8722 - val_loss: 0.3259\n",
            "Epoch 34/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9231 - loss: 0.1831 - val_accuracy: 0.8691 - val_loss: 0.4053\n",
            "\u001b[1m22/60\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9581 - loss: 0.1166Epoch 29/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9506 - loss: 0.1361 - val_accuracy: 0.8728 - val_loss: 0.3823\n",
            "Epoch 36/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9516 - loss: 0.1273 - val_accuracy: 0.8813 - val_loss: 0.3403\n",
            "Epoch 35/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9455 - loss: 0.1410 - val_accuracy: 0.8984 - val_loss: 0.3490\n",
            "\u001b[1m 1/60\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9688 - loss: 0.1113Epoch 35/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9400 - loss: 0.1524 - val_accuracy: 0.8393 - val_loss: 0.5173\n",
            "Epoch 30/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9621 - loss: 0.1171 - val_accuracy: 0.8959 - val_loss: 0.3595\n",
            "Epoch 36/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9529 - loss: 0.1221 - val_accuracy: 0.8594 - val_loss: 0.4085\n",
            "Epoch 36/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9554 - loss: 0.1230 - val_accuracy: 0.8844 - val_loss: 0.3817\n",
            "Epoch 37/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9501 - loss: 0.1453 - val_accuracy: 0.8618 - val_loss: 0.3876\n",
            "\u001b[1m12/60\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9180 - loss: 0.1878Epoch 34/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9310 - loss: 0.1673 - val_accuracy: 0.8582 - val_loss: 0.4183\n",
            "Epoch 31/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9552 - loss: 0.1200 - val_accuracy: 0.8801 - val_loss: 0.3361\n",
            "Epoch 37/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9572 - loss: 0.1184 - val_accuracy: 0.8971 - val_loss: 0.3555\n",
            "Epoch 38/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9396 - loss: 0.1542 - val_accuracy: 0.9014 - val_loss: 0.3348\n",
            "Epoch 37/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9263 - loss: 0.1783 - val_accuracy: 0.8698 - val_loss: 0.3916\n",
            "Epoch 32/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9375 - loss: 0.1546 - val_accuracy: 0.8844 - val_loss: 0.3375\n",
            "Epoch 35/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9561 - loss: 0.1199 - val_accuracy: 0.8935 - val_loss: 0.3333\n",
            "Epoch 38/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9641 - loss: 0.1072 - val_accuracy: 0.8929 - val_loss: 0.3346\n",
            "Epoch 39/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9581 - loss: 0.1179 - val_accuracy: 0.8606 - val_loss: 0.4341\n",
            "Epoch 38/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.9395 - loss: 0.1473 - val_accuracy: 0.8028 - val_loss: 0.5721\n",
            "Epoch 33/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9437 - loss: 0.1408 - val_accuracy: 0.8990 - val_loss: 0.3638\n",
            "Epoch 36/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9498 - loss: 0.1357 - val_accuracy: 0.8466 - val_loss: 0.4799\n",
            "Epoch 39/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9423 - loss: 0.1441 - val_accuracy: 0.8977 - val_loss: 0.3315\n",
            "\u001b[1m52/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9591 - loss: 0.1121Epoch 40/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9552 - loss: 0.1192 - val_accuracy: 0.8837 - val_loss: 0.3605\n",
            "Epoch 39/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9560 - loss: 0.1212 - val_accuracy: 0.8813 - val_loss: 0.3544\n",
            "Epoch 37/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9381 - loss: 0.1528 - val_accuracy: 0.8722 - val_loss: 0.3708\n",
            "Epoch 34/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9580 - loss: 0.1145 - val_accuracy: 0.8746 - val_loss: 0.3773\n",
            "Epoch 40/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9604 - loss: 0.1070 - val_accuracy: 0.8977 - val_loss: 0.3214\n",
            "\u001b[1m40/60\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9499 - loss: 0.1205Epoch 41/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9557 - loss: 0.1204 - val_accuracy: 0.8929 - val_loss: 0.3769\n",
            "Epoch 38/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9597 - loss: 0.1121 - val_accuracy: 0.8941 - val_loss: 0.3107\n",
            "Epoch 40/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9541 - loss: 0.1331 - val_accuracy: 0.8819 - val_loss: 0.3542\n",
            "Epoch 35/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9512 - loss: 0.1181 - val_accuracy: 0.9032 - val_loss: 0.3310\n",
            "\u001b[1m34/60\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9461 - loss: 0.1230Epoch 41/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9624 - loss: 0.1014 - val_accuracy: 0.8673 - val_loss: 0.3735\n",
            "Epoch 42/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9485 - loss: 0.1212 - val_accuracy: 0.8588 - val_loss: 0.4079\n",
            "Epoch 41/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9611 - loss: 0.1071 - val_accuracy: 0.8886 - val_loss: 0.3583\n",
            "Epoch 42/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9379 - loss: 0.1452 - val_accuracy: 0.8874 - val_loss: 0.3585\n",
            "Epoch 36/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9639 - loss: 0.0961 - val_accuracy: 0.8545 - val_loss: 0.4362\n",
            "Epoch 42/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9626 - loss: 0.0977 - val_accuracy: 0.8783 - val_loss: 0.3502\n",
            "\u001b[1m29/60\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9475 - loss: 0.1281Epoch 43/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9483 - loss: 0.1188 - val_accuracy: 0.8618 - val_loss: 0.4109\n",
            "\u001b[1m41/60\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9671 - loss: 0.0902Epoch 39/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9563 - loss: 0.1120 - val_accuracy: 0.9020 - val_loss: 0.3386\n",
            "\u001b[1m52/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9666 - loss: 0.0920Epoch 43/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9496 - loss: 0.1258 - val_accuracy: 0.8837 - val_loss: 0.3698\n",
            "Epoch 37/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9660 - loss: 0.0939 - val_accuracy: 0.9014 - val_loss: 0.3292\n",
            "Epoch 44/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9501 - loss: 0.1322 - val_accuracy: 0.7438 - val_loss: 0.9163\n",
            "\u001b[1m22/60\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9585 - loss: 0.1189Epoch 40/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9453 - loss: 0.1319 - val_accuracy: 0.9014 - val_loss: 0.3302\n",
            "Epoch 43/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9649 - loss: 0.0938 - val_accuracy: 0.8886 - val_loss: 0.3565\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9557 - loss: 0.1196Epoch 44/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9556 - loss: 0.1197 - val_accuracy: 0.8478 - val_loss: 0.4674\n",
            "\u001b[1m50/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9687 - loss: 0.0970Epoch 38/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9482 - loss: 0.1417 - val_accuracy: 0.8923 - val_loss: 0.3199\n",
            "\u001b[1m27/60\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9615 - loss: 0.0975Epoch 41/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9606 - loss: 0.0982 - val_accuracy: 0.9075 - val_loss: 0.3301\n",
            "Epoch 45/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9682 - loss: 0.0972 - val_accuracy: 0.9008 - val_loss: 0.3497\n",
            "Epoch 44/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9474 - loss: 0.1374 - val_accuracy: 0.8612 - val_loss: 0.3838\n",
            "Epoch 39/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.9613 - loss: 0.0994 - val_accuracy: 0.9014 - val_loss: 0.3312\n",
            "Epoch 45/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9713 - loss: 0.0896 - val_accuracy: 0.8515 - val_loss: 0.4501\n",
            "Epoch 42/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9616 - loss: 0.1058 - val_accuracy: 0.8923 - val_loss: 0.3716\n",
            "Epoch 45/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9586 - loss: 0.1084 - val_accuracy: 0.8880 - val_loss: 0.3578\n",
            "Epoch 46/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9547 - loss: 0.1158 - val_accuracy: 0.8643 - val_loss: 0.3959\n",
            "\u001b[1m43/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9454 - loss: 0.1325Epoch 40/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9469 - loss: 0.1285 - val_accuracy: 0.8880 - val_loss: 0.3716\n",
            "Epoch 43/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9694 - loss: 0.0877 - val_accuracy: 0.9081 - val_loss: 0.3343\n",
            "Epoch 46/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9575 - loss: 0.1169 - val_accuracy: 0.8710 - val_loss: 0.3948\n",
            "\u001b[1m20/60\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9716 - loss: 0.0802Epoch 41/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9624 - loss: 0.0960 - val_accuracy: 0.8807 - val_loss: 0.3523\n",
            "Epoch 46/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9576 - loss: 0.1051 - val_accuracy: 0.8874 - val_loss: 0.3534\n",
            "Epoch 47/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9592 - loss: 0.1067 - val_accuracy: 0.8771 - val_loss: 0.3742\n",
            "Epoch 44/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.9715 - loss: 0.0832 - val_accuracy: 0.8886 - val_loss: 0.3666\n",
            "Epoch 47/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9710 - loss: 0.0910 - val_accuracy: 0.8844 - val_loss: 0.3558\n",
            "Epoch 47/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9647 - loss: 0.1066 - val_accuracy: 0.9002 - val_loss: 0.3433\n",
            "\u001b[1m24/60\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9513 - loss: 0.1284Epoch 42/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9628 - loss: 0.0980 - val_accuracy: 0.9063 - val_loss: 0.3132\n",
            "Epoch 48/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9518 - loss: 0.1223 - val_accuracy: 0.8990 - val_loss: 0.3581\n",
            "Epoch 43/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9697 - loss: 0.0852 - val_accuracy: 0.8892 - val_loss: 0.3758\n",
            "Epoch 48/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9600 - loss: 0.1106 - val_accuracy: 0.8278 - val_loss: 0.5568\n",
            "Epoch 45/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9694 - loss: 0.0937 - val_accuracy: 0.8977 - val_loss: 0.3350\n",
            "Epoch 48/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9692 - loss: 0.0876 - val_accuracy: 0.9057 - val_loss: 0.3357\n",
            "Epoch 49/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9621 - loss: 0.0952 - val_accuracy: 0.8874 - val_loss: 0.3839\n",
            "Epoch 49/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9669 - loss: 0.0932 - val_accuracy: 0.9032 - val_loss: 0.3292\n",
            "Epoch 49/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9691 - loss: 0.0825 - val_accuracy: 0.9057 - val_loss: 0.3285\n",
            "Epoch 50/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9718 - loss: 0.0811 - val_accuracy: 0.8497 - val_loss: 0.4964\n",
            "\u001b[1m51/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9705 - loss: 0.0876Epoch 50/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.9700 - loss: 0.0826 - val_accuracy: 0.8911 - val_loss: 0.3467\n",
            "Epoch 50/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.9696 - loss: 0.0893 - val_accuracy: 0.8837 - val_loss: 0.4178\n",
            "Epoch 46/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9669 - loss: 0.0862 - val_accuracy: 0.8947 - val_loss: 0.3388\n",
            "Epoch 51/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9566 - loss: 0.1062 - val_accuracy: 0.8527 - val_loss: 0.5105\n",
            "Epoch 44/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9679 - loss: 0.0824 - val_accuracy: 0.9051 - val_loss: 0.3254\n",
            "Epoch 51/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9535 - loss: 0.1119 - val_accuracy: 0.8758 - val_loss: 0.4020\n",
            "Epoch 47/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9580 - loss: 0.1024 - val_accuracy: 0.9002 - val_loss: 0.3276\n",
            "\u001b[1m16/60\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9579 - loss: 0.0936Epoch 52/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9740 - loss: 0.0784 - val_accuracy: 0.8856 - val_loss: 0.3505\n",
            "Epoch 51/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9636 - loss: 0.0932 - val_accuracy: 0.8710 - val_loss: 0.4072\n",
            "Epoch 48/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.9632 - loss: 0.0981 - val_accuracy: 0.8886 - val_loss: 0.3546\n",
            "Epoch 45/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9646 - loss: 0.0860 - val_accuracy: 0.9002 - val_loss: 0.3378\n",
            "Epoch 53/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9675 - loss: 0.0788 - val_accuracy: 0.9063 - val_loss: 0.3311\n",
            "Epoch 52/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9708 - loss: 0.0845 - val_accuracy: 0.8965 - val_loss: 0.3788\n",
            "Epoch 52/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9567 - loss: 0.1051 - val_accuracy: 0.8953 - val_loss: 0.3489\n",
            "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9705 - loss: 0.0795Epoch 49/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9783 - loss: 0.0728 - val_accuracy: 0.8965 - val_loss: 0.3657\n",
            "Epoch 53/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9573 - loss: 0.1069 - val_accuracy: 0.9051 - val_loss: 0.3045\n",
            "Epoch 54/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9586 - loss: 0.1102 - val_accuracy: 0.8977 - val_loss: 0.3198\n",
            "Epoch 46/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9706 - loss: 0.0793 - val_accuracy: 0.9063 - val_loss: 0.3184\n",
            "Epoch 53/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9657 - loss: 0.0887 - val_accuracy: 0.9069 - val_loss: 0.3194\n",
            "Epoch 55/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9692 - loss: 0.0822 - val_accuracy: 0.9038 - val_loss: 0.3234\n",
            "Epoch 54/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9667 - loss: 0.0931 - val_accuracy: 0.9032 - val_loss: 0.3319\n",
            "Epoch 47/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9714 - loss: 0.0859 - val_accuracy: 0.8971 - val_loss: 0.3336\n",
            "Epoch 50/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9666 - loss: 0.0860 - val_accuracy: 0.9051 - val_loss: 0.3327\n",
            "Epoch 54/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9638 - loss: 0.0988 - val_accuracy: 0.8904 - val_loss: 0.3794\n",
            "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9752 - loss: 0.0732Epoch 51/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9766 - loss: 0.0756 - val_accuracy: 0.9057 - val_loss: 0.3221\n",
            "Epoch 56/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9630 - loss: 0.0938 - val_accuracy: 0.8643 - val_loss: 0.4568\n",
            "Epoch 48/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9750 - loss: 0.0735 - val_accuracy: 0.8752 - val_loss: 0.3827\n",
            "Epoch 55/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9743 - loss: 0.0727 - val_accuracy: 0.9087 - val_loss: 0.3222\n",
            "\u001b[1m18/60\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9796 - loss: 0.0562Epoch 55/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9726 - loss: 0.0774 - val_accuracy: 0.8746 - val_loss: 0.3940\n",
            "Epoch 52/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9782 - loss: 0.0659 - val_accuracy: 0.9057 - val_loss: 0.3307\n",
            "Epoch 57/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9685 - loss: 0.0880 - val_accuracy: 0.9002 - val_loss: 0.3476\n",
            "Epoch 56/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9627 - loss: 0.1027 - val_accuracy: 0.9026 - val_loss: 0.3538\n",
            "Epoch 49/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9471 - loss: 0.1263 - val_accuracy: 0.9002 - val_loss: 0.3468\n",
            "Epoch 50/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9697 - loss: 0.0798 - val_accuracy: 0.9081 - val_loss: 0.3223\n",
            "Epoch 57/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.9751 - loss: 0.0725 - val_accuracy: 0.9093 - val_loss: 0.3277\n",
            "Epoch 58/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9573 - loss: 0.1057 - val_accuracy: 0.9051 - val_loss: 0.3281\n",
            "Epoch 53/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - accuracy: 0.9732 - loss: 0.0733 - val_accuracy: 0.9044 - val_loss: 0.3098\n",
            "Epoch 56/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9728 - loss: 0.0783 - val_accuracy: 0.9117 - val_loss: 0.3105\n",
            "Epoch 58/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9669 - loss: 0.0828 - val_accuracy: 0.8941 - val_loss: 0.3551\n",
            "Epoch 54/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9674 - loss: 0.0880 - val_accuracy: 0.8959 - val_loss: 0.3216\n",
            "Epoch 51/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9766 - loss: 0.0675 - val_accuracy: 0.9069 - val_loss: 0.3207\n",
            "Epoch 59/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9620 - loss: 0.0977 - val_accuracy: 0.9002 - val_loss: 0.3495\n",
            "Epoch 57/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9761 - loss: 0.0686 - val_accuracy: 0.8929 - val_loss: 0.3748\n",
            "Epoch 55/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9738 - loss: 0.0676 - val_accuracy: 0.9008 - val_loss: 0.3528\n",
            "Epoch 60/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9710 - loss: 0.0840 - val_accuracy: 0.9081 - val_loss: 0.3145\n",
            "Epoch 52/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9786 - loss: 0.0639 - val_accuracy: 0.9142 - val_loss: 0.3363\n",
            "Epoch 59/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9746 - loss: 0.0782 - val_accuracy: 0.9069 - val_loss: 0.3219\n",
            "\u001b[1m56/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9787 - loss: 0.0672Epoch 56/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9715 - loss: 0.0746 - val_accuracy: 0.9026 - val_loss: 0.3295\n",
            "Epoch 60/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9753 - loss: 0.0679 - val_accuracy: 0.9081 - val_loss: 0.3414\n",
            "Epoch 58/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9736 - loss: 0.0747 - val_accuracy: 0.9026 - val_loss: 0.3134\n",
            "Epoch 53/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9785 - loss: 0.0673 - val_accuracy: 0.8746 - val_loss: 0.3993\n",
            "Epoch 61/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.9780 - loss: 0.0680 - val_accuracy: 0.9081 - val_loss: 0.3448\n",
            "Epoch 57/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9725 - loss: 0.0770 - val_accuracy: 0.9057 - val_loss: 0.3567\n",
            "Epoch 61/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9685 - loss: 0.0779 - val_accuracy: 0.9038 - val_loss: 0.3527\n",
            "Epoch 59/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9727 - loss: 0.0708 - val_accuracy: 0.9105 - val_loss: 0.3178\n",
            "\u001b[1m21/60\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9686 - loss: 0.0862Epoch 62/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9712 - loss: 0.0779 - val_accuracy: 0.9063 - val_loss: 0.3210\n",
            "Epoch 54/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9731 - loss: 0.0756 - val_accuracy: 0.9038 - val_loss: 0.3227\n",
            "Epoch 58/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9849 - loss: 0.0564 - val_accuracy: 0.9142 - val_loss: 0.3297\n",
            "Epoch 62/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9751 - loss: 0.0709 - val_accuracy: 0.9093 - val_loss: 0.3227\n",
            "Epoch 60/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9793 - loss: 0.0620 - val_accuracy: 0.9063 - val_loss: 0.3263\n",
            "Epoch 63/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.9627 - loss: 0.0955 - val_accuracy: 0.8813 - val_loss: 0.3910\n",
            "Epoch 55/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9816 - loss: 0.0595 - val_accuracy: 0.9124 - val_loss: 0.3349\n",
            "Epoch 59/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9746 - loss: 0.0726 - val_accuracy: 0.9069 - val_loss: 0.3127\n",
            "Epoch 61/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9719 - loss: 0.0711 - val_accuracy: 0.8777 - val_loss: 0.4287\n",
            "Epoch 63/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9794 - loss: 0.0631 - val_accuracy: 0.9099 - val_loss: 0.3324\n",
            "Epoch 64/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9725 - loss: 0.0708 - val_accuracy: 0.8637 - val_loss: 0.4737\n",
            "Epoch 60/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9798 - loss: 0.0546 - val_accuracy: 0.8947 - val_loss: 0.3662\n",
            "Epoch 62/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.9782 - loss: 0.0714 - val_accuracy: 0.9063 - val_loss: 0.3062\n",
            "Epoch 56/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9684 - loss: 0.0876 - val_accuracy: 0.9075 - val_loss: 0.3243\n",
            "Epoch 65/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9782 - loss: 0.0613 - val_accuracy: 0.9026 - val_loss: 0.3509\n",
            "Epoch 64/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9797 - loss: 0.0614 - val_accuracy: 0.9057 - val_loss: 0.3275\n",
            "Epoch 61/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9751 - loss: 0.0607 - val_accuracy: 0.9081 - val_loss: 0.3123\n",
            "Epoch 63/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9825 - loss: 0.0561 - val_accuracy: 0.8911 - val_loss: 0.3718\n",
            "Epoch 65/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9673 - loss: 0.1369 - val_accuracy: 0.9081 - val_loss: 0.3043\n",
            "Epoch 64/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9749 - loss: 0.0595 - val_accuracy: 0.9087 - val_loss: 0.3379\n",
            "Epoch 66/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9731 - loss: 0.0717 - val_accuracy: 0.9038 - val_loss: 0.3345\n",
            "Epoch 62/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9849 - loss: 0.0546 - val_accuracy: 0.8929 - val_loss: 0.3665\n",
            "\u001b[1m42/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9829 - loss: 0.0548Epoch 65/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9801 - loss: 0.0605 - val_accuracy: 0.9148 - val_loss: 0.3130\n",
            "Epoch 66/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9789 - loss: 0.0547 - val_accuracy: 0.7675 - val_loss: 0.9669\n",
            "Epoch 67/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9786 - loss: 0.0678 - val_accuracy: 0.9051 - val_loss: 0.3257\n",
            "Epoch 57/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9799 - loss: 0.0606 - val_accuracy: 0.9136 - val_loss: 0.3384\n",
            "Epoch 63/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9754 - loss: 0.0665 - val_accuracy: 0.9081 - val_loss: 0.3235\n",
            "Epoch 66/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9553 - loss: 0.1627 - val_accuracy: 0.9099 - val_loss: 0.3301\n",
            "Epoch 68/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9824 - loss: 0.0562 - val_accuracy: 0.9044 - val_loss: 0.3319\n",
            "\u001b[1m58/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9815 - loss: 0.0507Epoch 64/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9832 - loss: 0.0528 - val_accuracy: 0.8746 - val_loss: 0.4596\n",
            "Epoch 67/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9813 - loss: 0.0510 - val_accuracy: 0.9111 - val_loss: 0.3161\n",
            "Epoch 67/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9846 - loss: 0.0500 - val_accuracy: 0.9087 - val_loss: 0.3112\n",
            "Epoch 69/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9785 - loss: 0.0606 - val_accuracy: 0.9099 - val_loss: 0.3096\n",
            "Epoch 68/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9843 - loss: 0.0519 - val_accuracy: 0.9124 - val_loss: 0.3355\n",
            "Epoch 65/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.9700 - loss: 0.0795 - val_accuracy: 0.9093 - val_loss: 0.3228\n",
            "Epoch 58/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9819 - loss: 0.0542 - val_accuracy: 0.9075 - val_loss: 0.3225\n",
            "Epoch 68/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9721 - loss: 0.0693 - val_accuracy: 0.9002 - val_loss: 0.3328\n",
            "Epoch 66/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9795 - loss: 0.0517 - val_accuracy: 0.9111 - val_loss: 0.3389\n",
            "\u001b[1m26/60\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9884 - loss: 0.0489Epoch 67/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9845 - loss: 0.0494 - val_accuracy: 0.9099 - val_loss: 0.3014\n",
            "Epoch 69/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.9806 - loss: 0.0605 - val_accuracy: 0.9087 - val_loss: 0.3400\n",
            "Epoch 70/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9858 - loss: 0.0515 - val_accuracy: 0.9069 - val_loss: 0.3461\n",
            "Epoch 69/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.9695 - loss: 0.0832 - val_accuracy: 0.9051 - val_loss: 0.2970\n",
            "Epoch 59/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9832 - loss: 0.0518 - val_accuracy: 0.9099 - val_loss: 0.3309\n",
            "Epoch 70/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9780 - loss: 0.0613 - val_accuracy: 0.9160 - val_loss: 0.3397\n",
            "\u001b[1m40/60\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9868 - loss: 0.0446Epoch 68/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9767 - loss: 0.0679 - val_accuracy: 0.9124 - val_loss: 0.3377\n",
            "\u001b[1m14/60\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9792 - loss: 0.0624Epoch 60/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9809 - loss: 0.0552 - val_accuracy: 0.9069 - val_loss: 0.3378\n",
            "Epoch 70/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9798 - loss: 0.0612 - val_accuracy: 0.9020 - val_loss: 0.3667\n",
            "Epoch 71/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9870 - loss: 0.0454 - val_accuracy: 0.9136 - val_loss: 0.3114\n",
            "\u001b[1m 4/60\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9860 - loss: 0.0551Epoch 71/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9808 - loss: 0.0581 - val_accuracy: 0.9099 - val_loss: 0.3427\n",
            "Epoch 69/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9795 - loss: 0.0643 - val_accuracy: 0.9093 - val_loss: 0.3256\n",
            "Epoch 61/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9837 - loss: 0.0513 - val_accuracy: 0.9142 - val_loss: 0.3000\n",
            "Epoch 71/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9853 - loss: 0.0476 - val_accuracy: 0.9020 - val_loss: 0.3489\n",
            "Epoch 72/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9747 - loss: 0.0650 - val_accuracy: 0.9057 - val_loss: 0.3051\n",
            "Epoch 62/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9812 - loss: 0.0540 - val_accuracy: 0.9148 - val_loss: 0.3443\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9774 - loss: 0.0568Epoch 70/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9792 - loss: 0.0529 - val_accuracy: 0.9111 - val_loss: 0.3168\n",
            "Epoch 73/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9815 - loss: 0.0520 - val_accuracy: 0.9124 - val_loss: 0.3079\n",
            "\u001b[1m 5/60\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9927 - loss: 0.0281Epoch 72/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9774 - loss: 0.0568 - val_accuracy: 0.9136 - val_loss: 0.3119\n",
            "Epoch 72/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9726 - loss: 0.0718 - val_accuracy: 0.8929 - val_loss: 0.3633\n",
            "Epoch 63/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9832 - loss: 0.0486 - val_accuracy: 0.9184 - val_loss: 0.3183\n",
            "Epoch 74/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9764 - loss: 0.0664 - val_accuracy: 0.9081 - val_loss: 0.3456\n",
            "Epoch 73/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9829 - loss: 0.0543 - val_accuracy: 0.9117 - val_loss: 0.3117\n",
            "Epoch 71/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9834 - loss: 0.0508 - val_accuracy: 0.9111 - val_loss: 0.3062\n",
            "Epoch 73/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9847 - loss: 0.0486 - val_accuracy: 0.9057 - val_loss: 0.3240\n",
            "\u001b[1m22/60\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9811 - loss: 0.0432Epoch 74/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9802 - loss: 0.0499 - val_accuracy: 0.9111 - val_loss: 0.3216\n",
            "Epoch 74/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.9763 - loss: 0.0713 - val_accuracy: 0.8990 - val_loss: 0.3650\n",
            "Epoch 64/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9872 - loss: 0.0458 - val_accuracy: 0.9099 - val_loss: 0.3241\n",
            "Epoch 75/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9882 - loss: 0.0377 - val_accuracy: 0.9044 - val_loss: 0.3437\n",
            "Epoch 75/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.9862 - loss: 0.0408 - val_accuracy: 0.9069 - val_loss: 0.3459\n",
            "Epoch 72/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.9846 - loss: 0.0489 - val_accuracy: 0.9148 - val_loss: 0.3321\n",
            "\u001b[1m24/60\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9895 - loss: 0.0417Epoch 75/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9866 - loss: 0.0455 - val_accuracy: 0.8971 - val_loss: 0.3788\n",
            "Epoch 76/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9838 - loss: 0.0498 - val_accuracy: 0.9136 - val_loss: 0.3136\n",
            "Epoch 76/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9747 - loss: 0.0729 - val_accuracy: 0.9105 - val_loss: 0.2993\n",
            "\u001b[1m59/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9765 - loss: 0.0624Epoch 65/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.9830 - loss: 0.0488 - val_accuracy: 0.9130 - val_loss: 0.3143\n",
            "Epoch 73/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9767 - loss: 0.0621 - val_accuracy: 0.9124 - val_loss: 0.3320\n",
            "Epoch 76/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9789 - loss: 0.0603 - val_accuracy: 0.9111 - val_loss: 0.3182\n",
            "Epoch 66/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9867 - loss: 0.0455 - val_accuracy: 0.9172 - val_loss: 0.3095\n",
            "Epoch 77/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9836 - loss: 0.0458 - val_accuracy: 0.9117 - val_loss: 0.3177\n",
            "Epoch 77/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9840 - loss: 0.0456 - val_accuracy: 0.8984 - val_loss: 0.3845\n",
            "Epoch 77/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9801 - loss: 0.0593 - val_accuracy: 0.9142 - val_loss: 0.3250\n",
            "Epoch 78/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9842 - loss: 0.0440 - val_accuracy: 0.9160 - val_loss: 0.3498\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9837 - loss: 0.0496 - val_accuracy: 0.9178 - val_loss: 0.3073\n",
            "Epoch 78/80\n",
            "Epoch 78/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9773 - loss: 0.0598 - val_accuracy: 0.9051 - val_loss: 0.3169\n",
            "Epoch 67/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.9812 - loss: 0.0544 - val_accuracy: 0.9087 - val_loss: 0.3450\n",
            "\u001b[1m 1/60\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 0.0334Epoch 74/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9814 - loss: 0.0613 - val_accuracy: 0.9166 - val_loss: 0.3363\n",
            "\u001b[1m55/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9817 - loss: 0.0576Epoch 79/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9879 - loss: 0.0388 - val_accuracy: 0.9136 - val_loss: 0.3279\n",
            "Epoch 79/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9867 - loss: 0.0432 - val_accuracy: 0.9081 - val_loss: 0.3301\n",
            "Epoch 75/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9816 - loss: 0.0580 - val_accuracy: 0.9057 - val_loss: 0.3213\n",
            "Epoch 68/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9842 - loss: 0.0442 - val_accuracy: 0.9069 - val_loss: 0.3532\n",
            "\u001b[1m27/60\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9797 - loss: 0.0497Epoch 79/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9820 - loss: 0.0477 - val_accuracy: 0.9172 - val_loss: 0.3168\n",
            "Epoch 76/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9770 - loss: 0.0625 - val_accuracy: 0.9130 - val_loss: 0.3068\n",
            "Epoch 69/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9850 - loss: 0.0453 - val_accuracy: 0.9124 - val_loss: 0.3254\n",
            "Epoch 80/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.9812 - loss: 0.0515 - val_accuracy: 0.9148 - val_loss: 0.3073\n",
            "Epoch 80/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.9872 - loss: 0.0416 - val_accuracy: 0.9075 - val_loss: 0.3166\n",
            "Epoch 80/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.9815 - loss: 0.0572 - val_accuracy: 0.9178 - val_loss: 0.3260\n",
            "Epoch 77/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9764 - loss: 0.0631 - val_accuracy: 0.9117 - val_loss: 0.3265\n",
            "\u001b[1m 8/60\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9932 - loss: 0.0343Epoch 70/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9859 - loss: 0.0422 - val_accuracy: 0.9032 - val_loss: 0.3674\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9895 - loss: 0.0389 - val_accuracy: 0.9117 - val_loss: 0.3275\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9848 - loss: 0.0501 - val_accuracy: 0.9111 - val_loss: 0.2983\n",
            "Epoch 71/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.9867 - loss: 0.0368 - val_accuracy: 0.9093 - val_loss: 0.3213\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.9844 - loss: 0.0445 - val_accuracy: 0.9032 - val_loss: 0.3373\n",
            "Epoch 78/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.9849 - loss: 0.0476 - val_accuracy: 0.9093 - val_loss: 0.3171\n",
            "Epoch 72/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.9802 - loss: 0.0572 - val_accuracy: 0.9124 - val_loss: 0.3314\n",
            "Epoch 79/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9845 - loss: 0.0511 - val_accuracy: 0.9117 - val_loss: 0.3176\n",
            "Epoch 73/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9869 - loss: 0.0386 - val_accuracy: 0.9136 - val_loss: 0.3223\n",
            "Epoch 80/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9890 - loss: 0.0398 - val_accuracy: 0.9160 - val_loss: 0.3592\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9831 - loss: 0.0458 - val_accuracy: 0.9105 - val_loss: 0.3411\n",
            "Epoch 74/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9812 - loss: 0.0545 - val_accuracy: 0.9057 - val_loss: 0.3315\n",
            "Epoch 75/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9819 - loss: 0.0479 - val_accuracy: 0.8886 - val_loss: 0.4255\n",
            "Epoch 76/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9781 - loss: 0.0610 - val_accuracy: 0.9160 - val_loss: 0.2999\n",
            "Epoch 77/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9792 - loss: 0.0561 - val_accuracy: 0.9148 - val_loss: 0.3088\n",
            "Epoch 78/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9860 - loss: 0.0423 - val_accuracy: 0.9178 - val_loss: 0.3247\n",
            "Epoch 79/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9850 - loss: 0.0437 - val_accuracy: 0.9148 - val_loss: 0.3241\n",
            "Epoch 80/80\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9853 - loss: 0.0458 - val_accuracy: 0.8850 - val_loss: 0.4471\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9470 - loss: 0.1426\n",
            "trained local model is ready as 172.28.0.12:8083\n",
            "\n",
            "checking for other local models as 172.28.0.12:8083\n",
            "\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9333 - loss: 0.1780\n",
            "\u001b[1m227/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9414 - loss: 0.1552trained local model is ready as 172.28.0.12:8081\n",
            "\n",
            "checking for other local models as 172.28.0.12:8081\n",
            "\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9412 - loss: 0.1559\n",
            "trained local model is ready as 172.28.0.12:8085\n",
            "\n",
            "checking for other local models as 172.28.0.12:8085\n",
            "\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9452 - loss: 0.1509\n",
            "trained local model is ready as 172.28.0.12:8082\n",
            "\n",
            "checking for other local models as 172.28.0.12:8082\n",
            "\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9198 - loss: 0.2290\n",
            "trained local model is ready as 172.28.0.12:8084\n",
            "\n",
            "checking for other local models as 172.28.0.12:8084\n",
            "\n",
            "all local models are ready on the hashgraph\n",
            "\n",
            "election started\n",
            "all local models are ready on the hashgraph\n",
            "\n",
            "election started\n",
            "all local models are ready on the hashgraph\n",
            "\n",
            "election started\n",
            "all local models are ready on the hashgraph\n",
            "\n",
            "election started\n",
            "all local models are ready on the hashgraph\n",
            "\n",
            "election started\n",
            "sharding election is finished\n",
            "\n",
            "shard of 172.28.0.12:8081 is 0\n",
            "\n",
            "checking for other shard models as 172.28.0.12:8081\n",
            "\n",
            "sharding election is finished\n",
            "\n",
            "shard of 172.28.0.12:8082 is 1\n",
            "\n",
            "checking for other shard models as 172.28.0.12:8082\n",
            "\n",
            "sharding election is finished\n",
            "\n",
            "shard of 172.28.0.12:8083 is 1\n",
            "\n",
            "checking for other shard models as 172.28.0.12:8083\n",
            "\n",
            "sharding election is finished\n",
            "\n",
            "shard of 172.28.0.12:8084 is 0\n",
            "\n",
            "checking for other shard models as 172.28.0.12:8084\n",
            "\n",
            "sharding election is finished\n",
            "\n",
            "shard of 172.28.0.12:8085 is 0\n",
            "\n",
            "checking for other shard models as 172.28.0.12:8085\n",
            "\n",
            "172.28.0.12:8081 5\n",
            "aggregation done on aggregator as 172.28.0.12:8081\n",
            "\n",
            "starting next election for global aggregators\n",
            "\n",
            "election started\n",
            "172.28.0.12:8082 5\n",
            "aggregation done on aggregator as 172.28.0.12:8082\n",
            "\n",
            "starting next election for global aggregators\n",
            "\n",
            "election started\n",
            "172.28.0.12:8083 5\n",
            "aggregation done on aggregator as 172.28.0.12:8083\n",
            "\n",
            "starting next election for global aggregators\n",
            "\n",
            "election started\n",
            "172.28.0.12:8084 5\n",
            "aggregation done on aggregator as 172.28.0.12:8084\n",
            "\n",
            "starting next election for global aggregators\n",
            "\n",
            "election started\n",
            "172.28.0.12:8085 5\n",
            "aggregation done on aggregator as 172.28.0.12:8085\n",
            "\n",
            "starting next election for global aggregators\n",
            "\n",
            "election started\n",
            "globalling election is finished\n",
            "\n",
            "['172.28.0.12:8084', '172.28.0.12:8081', '172.28.0.12:8082', '172.28.0.12:8083', '172.28.0.12:8085']\n",
            "checking for other global models as 172.28.0.12:8081\n",
            "\n",
            "global aggregation done on global aggregator as 172.28.0.12:8081\n",
            "\n",
            "globalling election is finished\n",
            "\n",
            "['172.28.0.12:8084', '172.28.0.12:8081', '172.28.0.12:8082', '172.28.0.12:8083', '172.28.0.12:8085']\n",
            "checking for other global models as 172.28.0.12:8082\n",
            "\n",
            "global aggregation done on global aggregator as 172.28.0.12:8082\n",
            "\n",
            "globalling election is finished\n",
            "\n",
            "['172.28.0.12:8084', '172.28.0.12:8081', '172.28.0.12:8082', '172.28.0.12:8083', '172.28.0.12:8085']\n",
            "checking for other global models as 172.28.0.12:8083\n",
            "\n",
            "global aggregation done on global aggregator as 172.28.0.12:8083\n",
            "\n",
            "globalling election is finished\n",
            "\n",
            "['172.28.0.12:8084', '172.28.0.12:8081', '172.28.0.12:8082', '172.28.0.12:8083', '172.28.0.12:8085']\n",
            "checking for other global models as 172.28.0.12:8084\n",
            "\n",
            "global aggregation done on global aggregator as 172.28.0.12:8084\n",
            "\n",
            "globalling election is finished\n",
            "\n",
            "['172.28.0.12:8084', '172.28.0.12:8081', '172.28.0.12:8082', '172.28.0.12:8083', '172.28.0.12:8085']\n",
            "checking for other global models as 172.28.0.12:8085\n",
            "\n",
            "global aggregation done on global aggregator as 172.28.0.12:8085\n",
            "\n",
            "all global models are ready on hashgraph\n",
            "\n",
            "all global models are ready on hashgraph\n",
            "\n",
            "all global models are ready on hashgraph\n",
            "\n",
            "final global model is ready\n",
            "\n",
            "all global models are ready on hashgraph\n",
            "\n",
            "all global models are ready on hashgraph\n",
            "\n",
            "final global model is ready\n",
            "\n",
            "final global model is ready\n",
            "\n",
            "final global model is ready\n",
            "\n",
            "final global model is ready\n",
            "\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9273 - loss: 0.1921\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9384 - loss: 0.1685\n",
            "\u001b[1m116/230\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9477 - loss: 0.1432172.28.0.12:8081, accuracy: 0.929951012134552\n",
            "\u001b[1m 59/230\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9721 - loss: 0.0741172.28.0.12:8083, accuracy: 0.9024755358695984\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9321 - loss: 0.1915\n",
            "\u001b[1m132/230\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9393 - loss: 0.1579172.28.0.12:8084, accuracy: 0.9207018613815308\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9303 - loss: 0.1917\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9516 - loss: 0.1311\n",
            "172.28.0.12:8082, accuracy: 0.9400163292884827\n",
            "172.28.0.12:8085, accuracy: 0.9246463775634766\n"
          ]
        }
      ],
      "source": [
        "ports = [(i + 8081) for i in range(0, NODE_COUNT)]\n",
        "\n",
        "with open('peers.txt', \"w\") as f:\n",
        "  text = \"\"\n",
        "  for port in ports:\n",
        "    text += \"172.28.0.12:\" + str(port) + \" \" + str(port) + \"\\n\"\n",
        "  f.write(text)\n",
        "\n",
        "for index, port in enumerate(ports):\n",
        "  threading.Thread(target=main, args=(index, \"172.28.0.12:\" + str(port), port)).start()\n",
        "\n",
        "time.sleep(60 * 60)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}